<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读 | 南风er的小窝</title><meta name="keywords" content="mmwave雷达"><meta name="author" content="southner"><meta name="copyright" content="southner"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Abstract 与基于摄像头的方法相比，深度学习模型尚未探索使用汽车雷达进行目标检测。这可以归因于缺乏公共雷达数据集。在本文中，我们收集了一个新的雷达数据集，其中包含 Range-AzimuthDoppler 张量形式的雷达数据，以及用于动态道路用户的张量边界框、类别标签和笛卡尔鸟瞰图上的 2D  边界框范围图。为了构建数据集，我们提出了一种基于实例的自动注释方法。此外，提出了一种新颖的基于 R">
<meta property="og:type" content="article">
<meta property="og:title" content="《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读">
<meta property="og:url" content="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E3%80%8ARADDet-Range-Azimuth-Doppler-based-Radar-Object-Detection-for-Dynamic-Road-Users%E3%80%8B%E9%98%85%E8%AF%BB/">
<meta property="og:site_name" content="南风er的小窝">
<meta property="og:description" content="Abstract 与基于摄像头的方法相比，深度学习模型尚未探索使用汽车雷达进行目标检测。这可以归因于缺乏公共雷达数据集。在本文中，我们收集了一个新的雷达数据集，其中包含 Range-AzimuthDoppler 张量形式的雷达数据，以及用于动态道路用户的张量边界框、类别标签和笛卡尔鸟瞰图上的 2D  边界框范围图。为了构建数据集，我们提出了一种基于实例的自动注释方法。此外，提出了一种新颖的基于 R">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://picgo.southner.top/cover12.png">
<meta property="article:published_time" content="2022-05-17T04:55:39.000Z">
<meta property="article:modified_time" content="2022-05-17T04:55:39.000Z">
<meta property="article:author" content="southner">
<meta property="article:tag" content="mmwave雷达">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://picgo.southner.top/cover12.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E3%80%8ARADDet-Range-Azimuth-Doppler-based-Radar-Object-Detection-for-Dynamic-Road-Users%E3%80%8B%E9%98%85%E8%AF%BB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: southner","link":"链接: ","source":"来源: 南风er的小窝","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-05-17 12:55:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/southner.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://picgo.southner.top/cover12.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南风er的小窝</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-17T04:55:39.000Z" title="发表于 2022-05-17 12:55:39">2022-05-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-17T04:55:39.000Z" title="更新于 2022-05-17 12:55:39">2022-05-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Abstract">Abstract</h2>
<p>与基于摄像头的方法相比，深度学习模型尚未探索使用汽车雷达进行目标检测。这可以归因于缺乏公共雷达数据集。在本文中，我们收集了一个新的雷达数据集，其中包含 Range-AzimuthDoppler 张量形式的雷达数据，以及用于动态道路用户的张量边界框、类别标签和笛卡尔鸟瞰图上的 2D  边界框范围图。为了构建数据集，我们提出了一种基于实例的自动注释方法。此外，提出了一种新颖的基于 Range-Azimuth-Doppler  的多类目标检测深度学习模型。该算法是一种基于锚点的单阶段检测器，分别在 RangeAzimuth-Doppler 和笛卡尔域上生成 3D  边界框和 2D 边界框。我们提出的算法在 3D 边界框预测中以 0.3 的 IOU 实现了 56.3% 的 AP，在 2D 边界框预测中以  0.5 的 IOU 实现了 51.6% 的 AP。我们的数据集和代码可以在  <a href="https://github.com/ZhangAoCanada/RADDet.git">https://github.com/ZhangAoCanada/RADDet.git</a> 找到。</p>
<h2 id="Introduction-3">Introduction</h2>
<p>汽车雷达，也称为调频连续波 (FMCW) 雷达，已广泛应用于高级驾驶辅助系统  (ADAS)。与摄像头和激光雷达等其他传感器相比，雷达在恶劣天气和光照条件下具有鲁棒性，并且是一种较便宜的 [1]  传感器。雷达传感器的缺点是其低输出分辨率和高噪声水平。尽管如此，最近的研究 [2]、[3]、[4]  已经表明使用深度学习算法进行目标检测和姿态估计等各种任务的可行性。</p>
<p>来自 FMCW 雷达的原始数据（称为模数转换 (ADC) 信号）对于人类观察者来说很难读取。因此，它们通常被传递到雷达数字信号处理 (DSP)  中进行解释。稀疏点云表示是雷达 DSP 最流行的输出格式，因为它与激光雷达的输出格式相似。另一种广泛使用的输出格式是 3D  张量表示，用于说明范围、角度和速度方面的信息。这种格式通常称为距离-方位角-多普勒 (RAD) 频谱。图 1 左侧两列显示了一个示例。RAD  是用于提取点云表示的主要表示。由于 Range-Azimuth 维度采用极坐标的形式，因此通常将它们转换为笛卡尔坐标以获得更高的可读性。从  ADC 信号中提取 RAD 数据的方法有两类，即快速傅里叶变换 (FFT) 和 MUSIC [5]。尽管 MUSIC  提供了更高的精度，但它的计算成本很高。在这项研究中，我们研究了使用 FFT 实现的 RAD 光谱的目标检测。</p>
<p><img src="http://picgo.southner.top/image-20220426204516853.png" alt="image-20220426204516853"></p>
<p>图1：</p>
<p>我们数据集中的实例以及我们模型的预测。以距离-多普勒频谱 (A) 和距离-方位角频谱 (B) 表示的 3D 框。  © 笛卡尔坐标中框的 2D 表示。 (D) 用于可视化的摄像机视图。地面实况框用 facecolors 标记，预测没有  facecolors。</p>
<p>近年来，基于深度学习的目标检测算法在图像领域得到了广泛的探索。在雷达领域，虽然目标检测已经获得了一定程度的普及，但它仍然是一个没有被充分探索的领域。这是由于几个原因。首先，由于雷达数据的输入和输出表示不同，研究论文 [2]、[3]、[6]、[7]  的重点在这两者之间进行了划分。其次，缺乏提供原始输入表示和能力以对该领域的研究进行基准测试的公共数据集。因此，研究人员选择建立自己的数据集。在大多数雷达研究项目中可以发现的一个常见观察结果是它们只针对动态对象 [2]、[6]，因为动态对象的检测比静态对象更丰富。</p>
<p>在本文中，我们介绍了一个新的公开可用的数据集，并为动态道路使用者提出了一种新的对象检测模型。我们的贡献如下：</p>
<ul>
<li>介绍了一种新颖的数据集，其中包含以 RAD 表示形式的雷达数据，并带有针对各种对象类的相应注释。该数据集可用于该领域的未来研究。</li>
<li>提出了一种自动标注方法，可以在 RAD 数据的所有维度上以笛卡尔形式生成真实标签。</li>
<li>提出了一种新的雷达目标检测模型。我们的模型采用了基于 ResNet [8]  的主干。在雷达数据上对深度学习模型进行系统探索后，实现了骨干网的最终形式。受 YOLO head [9] 的启发，我们提出了一种新的双检测头，在 RAD 数据上具有 3D 检测头，在笛卡尔坐标数据上具有 2D 检测头。</li>
<li>我们提出的模型针对众所周知的基于图像的对象检测对应物进行了广泛评估。结果表明，我们的提议在使用雷达数据的目标检测任务中实现了最先进的性能。我们的结果的重要性表明，雷达是基于相机和激光雷达的目标检测方法的可行竞争对手。</li>
</ul>
<h2 id="Related-Work">Related Work</h2>
<p>自主雷达研究的一个常见问题是缺乏适当的公共数据集。这是由于雷达硬件差异和雷达本身的高度可配置特性。例如，不同数量的板载发射器和接收器将导致不同的数据分辨率。此外，随着频率扫描幅度和采样率的不同，最大检测范围和距离分辨率将完全不同。因此，大多数雷达研究人员选择使用传感器融合技术自己创建数据集。</p>
<p>在之前的工作 [3]、[10]、[4]、[6]、[11]、[2] 中，相机和激光雷达与雷达一起用于构建数据集。为了提高数据集的质量，一些研究人员[1]甚至使用多个高精度传感器来标注雷达数据，即激光雷达、合成孔径雷达（SAR）和相机。</p>
<p>除了采用不同的传感器外，上述所有数据集的另一大区别是输入雷达数据格式。一般来说，它可以分为两类：基于簇的雷达输入格式和基于频谱的雷达输入格式。</p>
<p>基于簇的输入格式是包含点簇的数据格式，每个点都说明对象的位置。为了生成这样的格式，需要应用一些传统的基于集群的预处理方法。舒曼等人[12]  使用 DBSCAN [13]  来区分和提取雷达帧中的所有实例，然后用相机帧中的相应对象注释每个实例。基于集群的方法的一个挑战是，由于有限的范围分辨率和高噪声水平，数据可能被错误地合并或分离。帕尔菲等人 [6] 通过将裁剪的基于频谱的数据添加到集群并使用 3D 卷积来处理输入雷达立方体来设法克服此类问题。</p>
<p>基于频谱的输入格式（如 RAD  频谱）保持输入数据的一致性，无需任何离散化。这将提高大多数深度学习算法的性能。但是，它也增加了输入数据的复杂性，这可能会影响这些算法的运行速度。布罗德斯基等人 [3] 使用 Range-Doppler-Angles 频谱成功地进行了 3D  点云分割和姿态估计，其中角度代表方位角和仰角的组合。诺鲁齐等人[4] 使用 Range-Azimuth-Doppler  频谱作为自由空间分割的输入。少校等人 [11] 将 Range-Azimuth-Doppler 输入沿 3  个轴分开，并在将它们集成在一起之前将它们馈送到网络中。 Range-Azimuth 谱在 [10]、[14]、[2] 中用于物体检测和分类。</p>
<p>基于不同类型的输入，来自计算机视觉领域的各种基本模型与雷达数据一起使用。对于基于簇的输入，Schumann 等人 [7] 探索来自  PointNet++ [15] 的多尺度分组模块 (MSG)，用于基于点云的分割。对于基于频谱的输入，VGG [16] 被选为 [14]  中的基础模型。布罗德斯基等人[3] 构建基于 Faster-RCNN [17] 的高级架构。 U-Net [18] 和 FCN [19]  架构是近期雷达研究项目 [2]、[20]、[4] 中最受欢迎的架构。</p>
<p>对于目标检测，检测头是研究最多的课题之一。典型的基于锚的一级检测头[21]、[9]、[22]在该领域仍然处于领先地位。另一方面，无锚单阶段检测头[23]最近获得了一定的普及，并且性能正在逐渐赶上基于锚的检测头。自注意力层 [29]、[30] 在实现该任务的进一步改进方面显示出越来越大的潜力。两级检测头 [17]  始终被认为能够实现更高的性能，但比一级检测头慢得多。在雷达研究中，[2] 提出了一种面向概率的目标检测头，用于面向 2D 框检测。</p>
<p>与以往的研究项目相比，我们提出的数据集采用了雷达数据的全尺寸信息，包括速度、距离、角度和笛卡尔坐标中的相应位置。此外，我们选择 ResNet  [8] 和 YOLO [9] 作为我们提出的深度学习算法的基础模型。作为回报，它以最佳运行时速度提高了雷达数据上的目标检测性能。</p>
<p><img src="http://picgo.southner.top/image-20220426211029537.png" alt="image-20220426211029537"></p>
<p>图 2：</p>
<p>提出的用于ground truth生成的自动注释方法，包括增强的雷达预处理和立体深度估计。</p>
<h2 id="Dataset-Preparation">Dataset Preparation</h2>
<p>在本节中，我们将介绍雷达和立体摄像机的硬件设置。我们提出了一种新的自动注释方法来解决具有挑战性的雷达注释任务。然后手动验证提取的注释以确保数据集的质量。最后，我们报告数据集的统计分析。</p>
<h3 id="A-Hardware-Setup">A. Hardware Setup</h3>
<p>用于数据收集的传感器包括德州仪器 AWR1843-BOOST2 雷达和一对来自 The Imaging Source 的 DFK  33UX2733 立体相机。在[24]的指导下，使用自制的三面角反射器实现传感器校准。为校准目标设置随机位置，与传感器的距离从 5m 到  50m。使用最小二乘优化计算从 3D 立体帧到鸟瞰雷达帧的投影矩阵。从雷达捕获的原始 ADC 数据具有 (256,8,64) 的形状。</p>
<h3 id="B-Annotation-Method">B. Annotation Method</h3>
<p>FMCW雷达的传统DSP分为两个步骤。首先，对接收到的 ADC 信号的每个维度进行 FFT。此步骤的主要输出是 RAD  频谱。在我们的研究中，在计算方位角维度上的 FFT 时使用了零填充，并且生成的 RAD 输出具有 (256,256,64)  的形状。其次，恒定误报率 (CFAR) 用于滤除距离多普勒维度上的噪声信号。有两种主要的 CFAR 算法，即 Cell-Averaging  CFAR (CA-CFAR) 和 Ordered-Statistic CFAR (OS-CFAR)。由于其高质量的输出，OSCFAR  通常更适合学术用途，而 CA-CFAR  由于速度快而经常在行业中使用。此步骤的输出通常转换为笛卡尔坐标并呈现为点云，这是各种应用中基于集群的雷达数据分析的基础。</p>
<p>通过分析传统雷达DSP的输出，我们发现动态道路使用者的检测率明显高于静态道路使用者。这是因为动态道路使用者通常在多普勒轴上拥有更丰富的信息。因此，我们仅将目标设定为动态道路使用者。另一方面，传统的 OS-CFAR  在某些情况下即使使用微调参数也会产生错误检测。例如，当对象太大时它可能会忽略点，或者它可能会将噪声点错误地标记为检测。我们提出的注释方法可以有效地解决这些问题。</p>
<p>在 2D OS-CFAR 的距离多普勒 (RD)  输出上，由于多普勒轴上的速度相干性，可以轻松检测车辆等刚体。对于行人来说，不同身体部位的不同运动可能会导致 RD 谱 [3]  上的各种输出模式。然而，当雷达的距离分辨率达到一定水平时，很难观察到人体运动的复杂性。因此，它们也可以被视为刚体。图 2 显示了一个示例。出现在 RD 谱上的刚体的一个特性是，尽管物体和雷达之间存在角度差异，但它们通常呈现为线性模式。因此，通过连接 RD  光谱上的离散模式，我们成功地丰富了传统 2D OS-CFAR 的检测率。</p>
<p>然而，当物体以相似的速度在相同的范围内时，这种方法的检测效果很差。 DBSCAN [13] 可以有效缓解此类问题。这样，我们可以从 RAD 数据中精确地提取对象实例。所提出的雷达预处理方法的数据流如图2所示。</p>
<p>通过我们的提议，可以很容易地从 RAD  频谱中提取雷达实例。然而，仅对雷达实例进行分类是一项具有挑战性的任务。在这项研究中，我们依靠立体视觉进行类别标注。整个过程描述如下。首先，使用  OpenCV4 的半全局块匹配算法从校正后的立体图像对生成视差图。然后，将预训练的 Mask-RCNN [25]  模型应用于左侧图像以提取实例分割掩码。然后将预测掩码投影到视差图上。最后，使用三角测量，生成具有预测类别的实例点云输出。之后，使用在 III-A 中获得的投影矩阵将点云实例转换为雷达帧。</p>
<p>我们的自动注释方法是使用获得的雷达和立体实例开发的。图 2 显示了整个流程。使用这种方法，我们可以检索数据集中大约 75%  的对象的注释。多种因素可能导致注释中的错误，例如由于传感器噪声导致的雷达实例提取错误、立体相机的深度估计错误以及 Mask-RCNN [25]  的预测错误。此外，由于立体摄像机的视野 (FOV)  远小于雷达，因此有一定数量的物体未标记。为了解决这些问题，在自动注释过程之后进行手动更正以生成数据集。</p>
<h3 id="C-Dataset-Analysis">C. Dataset Analysis</h3>
<p>数据采集会议在 9 月至 10 月期间在多个随机地点在阳光明媚的天气条件下进行。传感器设置在人行道上并面向主要道路，如图 1 所示。去除损坏的帧后，总共收集了 10158 帧来构建我们的数据集。至于数据集的统计分析，图3显示了细节。</p>
<p>我们使用按类别随机抽样将数据集分为训练集和测试集，比例分别为 80% 和 20%。这确保了我们的训练集和测试集都遵循图 3 所示的整体分布。此外，我们在实验期间将训练集分成 90% 用于训练，10% 用于验证，以找到最佳系数和模型。</p>
<h2 id="RADDet">RADDet</h2>
<p>最先进的基于图像的目标检测算法由 3 个部分组成，骨干、颈部和检测头 [9]、[23]、[22]。受此启发，我们基于广泛使用的 ResNet  [8]  制定了我们的骨干网络。在图像域中，颈部层用于提取多个级别的输出，以处理对象的尺度变化。然而，与图像不同的是，由于透视几何，距离会改变物体的大小，雷达揭示了物体的真实比例。因此，我们的研究中不考虑多分辨率颈部层。最后，我们提出了一种基于著名的基于锚的算法 YOLO [9] 的新型双检测头。图 4 显示了我们提出的架构的数据流。详细信息将在以下部分中介绍。</p>
<p><img src="http://picgo.southner.top/image-20220426224807020.png" alt="image-20220426224807020"></p>
<p>图 3：</p>
<p>左：对象数量在所有类别中的分布。右图：所有对象的范围分布。</p>
<h3 id="A-Global-Normalization-of-the-Input">A. Global Normalization of the Input</h3>
<p>我们模型的原始输入是大小为 (256,256,64) 的 Range-Azimuth-Doppler 张量，以复数形式表示。正如在传统雷达  DSP 中所做的那样，我们首先提取原始输入的幅度并记录它。为了对输入进行归一化，在整个数据集 $D_{dataset}$上搜索平均值 $Vmean $ 和方差值 $Vvariance$。然后，将每个输入张量归一化为等式 1。</p>
<p><img src="http://picgo.southner.top/image-20220426224951911.png" alt="image-20220426224951911"></p>
<p>其中，$I_{inorm}$ 是下一步中骨干网的输入。</p>
<h3 id="B-RadarResNet">B. RadarResNet</h3>
<p>如上所述，输入与基于图像的方法中使用的彩色图像完全不同。为了使 2D 卷积层适应我们的任务，我们将 RangeAzimuth  轴设置为输入维度，将多普勒轴设置为原始通道大小。在架构搜索过程中考虑了通道扩展和特征图下采样方法。经过大量的架构探索和实验，我们最终确定了基于  ResNet [8] 的骨干网络，并将其命名为 RadarResNet。图 4 显示了由两种类型的块组成的  RadarResNet，即残差块和下采样块。残差块与 ResNet  中的基本残差块具有相同的结构，下采样块由一个最大池化层组成。激活函数设置为校正线性单元，并且在残差块中的每个卷积层之后应用批量归一化  [26]。提议的主干的最终输出大小为 (16,16,256)。</p>
<p><img src="http://picgo.southner.top/image-20220426225155300.png" alt="image-20220426225155300"></p>
<h3 id="C-Dual-Detection-Head">C. Dual Detection Head</h3>
<p>我们的检测头由两个分支组成：一个 3D 和一个 2D 检测头。它们都是基于锚的方法，并且具有与 YOLO [9]  相似的结构。在我们的研究中，通过对所有地面真值框使用 K-means 聚类，为 3D 和 2D 检测头分支定义了 6 个<strong>锚框</strong>，错误率阈值设置为  10%。</p>
<h4 id="1-3D-Detection-Head">1) 3D Detection Head</h4>
<p>由于我们的 3D 检测头的输出是 3D 边界框，因此对传统的 YOLO Head  进行了一些修改以适应我们的任务。首先，以与其他维度相同的步幅计算第三维多普勒维度的输出大小。在我们的例子中，多普勒轴的输出大小为  4。其次，不是将特征图卷积为 (16,16,num_of_anchors × (5 + num_of_classes)) [9]，而是 3D  头部将特征图处理为 (16 ,16,4 × num_of_anchors × (7 + num_of_classes))，其中 7 代表  objectness 和 3D box 信息。 3D 框信息由 3D 中心点 [x, y, z] 和大小 [w, h, d]  组成。最后，原始检测输出被重新整形为最终输出格式（16,16,4,num_of_anchors,7+num_of_classes），然后再输入非最大抑制（NMS）。其他操作，如框位置计算和解释，与 YOLO [9] 的结构相同。为方便起见，我们将 3D 检测头命名为 RAD YOLO Head。</p>
<h4 id="2-2D-Detection-Head">2) 2D Detection Head</h4>
<p>二维检测头由两部分组成；一个坐标变换层，将特征图从极坐标表示转换为笛卡尔形式，以及一个经典的 YOLO Head [9]。坐标变换层的结构如图5所示。</p>
<p>传统上，从距离和方位角域 [r,θ] 到由 [x,z] 表示的笛卡尔宽度和深度域的坐标变换由以下等式表示。</p>
<p><img src="http://picgo.southner.top/image-20220426225558317.png" alt="image-20220426225558317"></p>
<p><img src="http://picgo.southner.top/image-20220426225612913.png" alt="image-20220426225612913"></p>
<p>这种非线性变换可以沿笛卡尔形式的宽度维度将输入的大小加倍。</p>
<p>我们的坐标变换层受到传统方法的启发。输入特征图的形式为 [r,θ]，大小为 (16,16,256)。它们可以解释为 256 个形状为  (16,16) 的 RA 特征图。每个 RA 特征图被单独馈送到两个完全连接的层以进行非线性变换。然后将这些特征的输出重新整形为 (32,16) 并连接以构建大小为 (32,16,256) 的笛卡尔特征图。最后，由于它们是低级特征图，一个与 ResNet [8]  中的基本残差块具有相同结构的残差块被构造用于后处理。然后将转换后的输出直接输入 YOLO Head 进行 2D 框预测。</p>
<h3 id="D-Loss-Functions">D. Loss Functions</h3>
<p>YOLO Head 的输出通常分为 3 个任务，即框回归、对象预测和分类 [9]。已经为这 3 个任务探索了各种损失函数以提高性能。在我们的研究中，总损失 $Ltotal$ 表示为公式 3。</p>
<p><img src="http://picgo.southner.top/image-20220426225823522.png" alt="image-20220426225823522"></p>
<p>框回归损失 $Lbox$ 的损失函数选自 [27]。 Focal Loss [22] 用于训练对象预测损失 $ Lobj$。然而，为了消除非对象预测的优势，我们将 Focal Loss 中负样本的 α 系数设置为 0.01。对于分类损失  $Lclass$，我们使用交叉熵 [28] 作为损失函数。在训练过程中，我们发现$Lbox$ 很容易支配总损失值。因此，我们为 box loss  设置了另一个系数 β = 0.1。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://southner.top">southner</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E3%80%8ARADDet-Range-Azimuth-Doppler-based-Radar-Object-Detection-for-Dynamic-Road-Users%E3%80%8B%E9%98%85%E8%AF%BB/">http://southner.top/article/科研/论文阅读/2022/《RADDet-Range-Azimuth-Doppler-based-Radar-Object-Detection-for-Dynamic-Road-Users》阅读/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://southner.top" target="_blank">南风er的小窝</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/mmwave%E9%9B%B7%E8%BE%BE/">mmwave雷达</a></div><div class="post_share"><div class="social-share" data-image="http://picgo.southner.top/cover12.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E3%80%8AMultiperson-Continuous-Tracking-and-Identification-From-mm-Wave-Micro-Doppler-Signatures%E3%80%8B%E9%98%85%E8%AF%BB/" title="《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读"><img class="cover" src="http://picgo.southner.top/cover7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-06</div><div class="title">《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读</div></div></a></div><div><a href="/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E3%80%8AmmSense-Multi-Person-Detection-and-Identification-via-mmWave-Sensing-19%E3%80%8B%E9%98%85%E8%AF%BB/" title="《mmSense: Multi-Person Detection and Identification via mmWave Sensing 19》阅读"><img class="cover" src="http://picgo.southner.top/cover14.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-23</div><div class="title">《mmSense: Multi-Person Detection and Identification via mmWave Sensing 19》阅读</div></div></a></div><div><a href="/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/2022/RADDet%E5%B7%A5%E4%BD%9C%E5%A4%8D%E7%8E%B0/" title="RADDet工作复现"><img class="cover" src="http://picgo.southner.top/cover13.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-05</div><div class="title">RADDet工作复现</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction-3"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-text">Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dataset-Preparation"><span class="toc-text">Dataset Preparation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Hardware-Setup"><span class="toc-text">A. Hardware Setup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Annotation-Method"><span class="toc-text">B. Annotation Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-Dataset-Analysis"><span class="toc-text">C. Dataset Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RADDet"><span class="toc-text">RADDet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Global-Normalization-of-the-Input"><span class="toc-text">A. Global Normalization of the Input</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-RadarResNet"><span class="toc-text">B. RadarResNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-Dual-Detection-Head"><span class="toc-text">C. Dual Detection Head</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3D-Detection-Head"><span class="toc-text">1) 3D Detection Head</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2D-Detection-Head"><span class="toc-text">2) 2D Detection Head</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#D-Loss-Functions"><span class="toc-text">D. Loss Functions</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By southner</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="http://www.beian.miit.gov.cn/"><img class="icp-icon" src="https://pic3.zhimg.com/80/v2-d0289dc0a46fc5b15b3363ffa78cf6c7.png"><span>陕ICP备20012321号</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>