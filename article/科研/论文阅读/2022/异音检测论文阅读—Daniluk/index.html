<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>异音检测论文阅读—Daniluk | 南风er的小窝</title><meta name="keywords" content="异音检测"><meta name="author" content="southner"><meta name="copyright" content="southner"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="2.Daniluk ENSEMBLE OF AUTO-ENCODER BASED AND WAVENET LIKE SYSTEMS FOR UNSUPERVISED ANOMALY DETECTION  Introduction我们的解决方案包括三类模型: Heteroskedastic Variational Auto-encoders, ID Conditioned Auto-encoders">
<meta property="og:type" content="article">
<meta property="og:title" content="异音检测论文阅读—Daniluk">
<meta property="og:url" content="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E2%80%94Daniluk/">
<meta property="og:site_name" content="南风er的小窝">
<meta property="og:description" content="2.Daniluk ENSEMBLE OF AUTO-ENCODER BASED AND WAVENET LIKE SYSTEMS FOR UNSUPERVISED ANOMALY DETECTION  Introduction我们的解决方案包括三类模型: Heteroskedastic Variational Auto-encoders, ID Conditioned Auto-encoders">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://picgo.southner.top/cover8.png">
<meta property="article:published_time" content="2022-02-06T04:48:46.000Z">
<meta property="article:modified_time" content="2022-06-17T08:51:35.881Z">
<meta property="article:author" content="southner">
<meta property="article:tag" content="异音检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://picgo.southner.top/cover8.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E2%80%94Daniluk/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: southner","link":"链接: ","source":"来源: 南风er的小窝","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '异音检测论文阅读—Daniluk',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-06-17 16:51:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/southner.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://picgo.southner.top/cover8.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南风er的小窝</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">异音检测论文阅读—Daniluk</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-06T04:48:46.000Z" title="发表于 2022-02-06 12:48:46">2022-02-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-17T08:51:35.881Z" title="更新于 2022-06-17 16:51:35">2022-06-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="异音检测论文阅读—Daniluk"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="2-Daniluk"><a href="#2-Daniluk" class="headerlink" title="2.Daniluk"></a>2.Daniluk</h2><blockquote>
<p><strong>ENSEMBLE OF AUTO-ENCODER BASED AND WAVENET LIKE SYSTEMS FOR UNSUPERVISED ANOMALY DETECTION</strong></p>
</blockquote>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>我们的解决方案包括三类模型: <strong>Heteroskedastic Variational Auto-encoders</strong>, <strong>ID Conditioned Auto-encoders</strong> and a <strong>WaveNet like network</strong>. 使用一个用于消除噪音的U-Net对噪音recording进行预处理，模型使用从AudioSet获得的有噪音样本进行训练。模型可以在OpenL3 embeddings或log-mel power spectra上工作。</p>
<p>Heteroskedastic VAEs具有非标准的损失函数，利用模型自身的误差估计来衡量典型的MSE损耗。为每个machine type独立选择模型结构，即层的大小，latent space的维度和误差估计网络的大小。</p>
<p>ID Conditioned AEs是针对开放集合识别而设计的类条件自动编码器方法的改编。假设非异常样本构成不同的ID，我们将机器ID作为标签应用于类条件自动编码器。我们的方法省略了分类子任务，将学习过程简化为一次运行。通过为不匹配的标签固定一个目标，我们进一步简化了学习过程。异常预测要么是由于糟糕的重建或样本被归结到错误的machine id。</p>
<p>WaveNet like network是基于卷积神经网络。该模型的架构受到WaveNet的启发，并使用随膨胀率增长的causal convolutional layers 。它的工作原理是预测给定录音的谱图中的下一帧。根据重建误差得到异常评分。</p>
<p>我们分别给出了每一种模型得到的结果，以及通过平均每个模型计算的异常分数得到的一个集合的结果。</p>
<h3 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h3><h4 id="Heteroskedastic-Variational-Auto-encoders"><a href="#Heteroskedastic-Variational-Auto-encoders" class="headerlink" title="Heteroskedastic Variational Auto-encoders"></a>Heteroskedastic Variational Auto-encoders</h4><h5 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h5><p>一个典型的Variational Auto-Encoder[5]包括两个网络:编码器(E)将输入<strong>特征向量</strong>$X$映射到 latent space上的正态分布($N(µ，σ)$)，其中$µ，σ&#x3D; E(X)$是一个k维向量，k是 latent space的维度;以及Decoder (D)，将 **latent vector $z$<strong>映射到特征空间中的一个</strong>重构点$(\hat{X}&#x3D;D(Z))$**。</p>
<p>采样操作是施加在编码器返回的分布上的，以获得latent space中的实际点，并将这些实际点喂给解码器。损失函数由两项组成:$D_{KL}(N(µ，σ)||N(0,1)) + MSE(X，\hat{X})$。这是variational inference的一种特殊情况，在这种情况下，特征空间($p(X)$)上难以处理的概率分布被近似为最大化:</p>
<p>$$<br>log\ p(X)\ &gt;&#x3D;\ E_{q(Z|X)}log\ p(X|Z)\ +\ D_{KL}(q(Z|X)||p(Z))</p>
<p>$$</p>
<p>Distribution $q(Z|X)$is normal with diagonal covariance matrix and parameters computed by the encoder,$p(Z)$ is $N(0,1)$, and $p(X|Z)$ is normal with mean given by the decoder $(\hat{X})$ and unit variance. The latter results with the MSE$(X,\hat{X})$ term in the loss function.</p>
<p>分布$q(Z|X)$为正态分布，有对角协方差矩阵，参数由编码器计算，$p(Z)$为$N(0,1)$，$p(X|Z)$为正态分布，均值由解码器$D(\hat{X})$给出，单位方差。后者导致损失函数中的$MSE(X，\hat{X})$项。</p>
<blockquote>
<p>假设一个向量$x$服从均值向量为$u$、协方差矩阵为$\sum$ 的多元正态分布(multi-variate Gaussian distribution)，则</p>
<p>$$<br>p(x)&#x3D;|2\pi \sum|^{-1&#x2F;2}exp(-\frac{1}{2}(x-u)^T(\sum)^{-1}(x-u))</p>
<p>$$</p>
</blockquote>
<blockquote>
<p>[5] D. P . Kingma and M. Welling, “<strong>An introduction to variational autoencoders</strong>,”Foundations and Trends in Machine Learning, vol. 12, no. 4, p. 307–392, 2019. [Online]. Available: <a href="http://dx.doi.org/10.1561/2200000056">http://dx.doi.org/10.1561/2200000056</a></p>
<blockquote>
<p><a href="https://www.jianshu.com/p/43318a3dc715">K-L散度（相对熵）</a> 从使用二项分布来模拟一个蠕虫牙齿分布开始，讲如何使用KL散度优化模型</p>
<p><code>Kullback-Leibler Divergence</code>，即<code>K-L散度</code>，是一种<strong>量化两种概率分布P和Q之间差异</strong>的方式，又叫<code>相对熵</code>。在概率学和统计学上，我们经常会使用一种<code>更简单的、近似的分布</code>来替代<code>观察数据</code>或<code>太复杂的分布</code>。K-L散度能帮助我们度量使用一个分布来近似另一个分布时所损失的信息量。</p>
<p>设<code>p</code>为观察得到的概率分布，<code>q</code>为另一分布来近似<code>p</code>，则<code>p</code>、<code>q</code>的<code>K-L散度</code>为：</p>
<p>$$<br>D_{KL}(p||q)&#x3D;\sum_{i&#x3D;1}^Np(x_i)\cdot(log\ p(x_i)-log\ q(x_i))</p>
<p>$$</p>
<p>显然，根据上面的公式，K-L散度其实是数据的原始分布p和近似分布q之间的对数差值的期望。如果继续用<code>2</code>为底的对数计算，则<strong>K-L散度值表示信息损失的二进制位数</strong>。下面公式以期望表达K-L散度：</p>
<p>$$<br>D_{KL}(p||q)&#x3D;E(log\ p(x_i)-log\ q(x_i))</p>
<p>$$</p>
<p>一般，K-L散度以下面的书写方式更常见：</p>
<p>$$<br>D_{KL}(p||q)&#x3D;\sum_{i&#x3D;1}^Np(x_i)\cdot log\frac{p(x_i)}{q(x_i)}</p>
<p>$$</p>
<p>可以使用K-L散度作为目标方程来优化模型。神经网络即是构造函数$f(x)$来逼近真实函数$g(x)$，而K-L散度用来度量在逼近一个分布时的信息损失量。K-L散度能够赋予神经网络近似表达非常复杂数据分布的能力。</p>
<p>变分自编码器（Variational Autoencoders，VAEs）是一种能够学习最佳近似数据集中信息的常用方法，<a href="https://arxiv.org/abs/1606.05908">Tutorial on Variational Autoencoders 2016</a>是一篇关于VAEs的非常不错的教程，里面讲述了如何构建VAE的细节。 <a href="https://medium.com/@dmonn/what-are-variational-autoencoders-a-simple-explanation-ea7dccafb0e3">What are Variational Autoencoders? A simple explanation</a>简单介绍了VAEs，<a href="https://blog.keras.io/building-autoencoders-in-keras.html">Building Autoencoders in Keras</a>介绍了如何利用Keras库实现几种自编码器。</p>
<p>notes:</p>
<ul>
<li>散度并非距离，其不满足对称性。</li>
</ul>
</blockquote>
</blockquote>
<p>在我们的解决方案中，我们通过改变$p(X|Z)$的结构改进了vanilla VAE。我们使用一个解码器的额外输出代替了单位方差。如此解码器不仅重建($\hat X$)，同时重建它的精度$-\hat X,\hat \sigma &#x3D; D(Z)$.</p>
<p><img src="http://picgo.southner.top/image-20211215150147825.png" alt="image-20211215150147825"></p>
<p>在省略不必要的常数后，我们会得到以下损失函数:</p>
<p><img src="http://picgo.southner.top/image-20211215150230683.png" alt="image-20211215150230683"></p>
<p>$\beta$是一个附加的参数，它有助于实现损失组件之间的平衡。</p>
<p>我们已经通过实验确定，当仅对正常数据进行训练模型时，wMSE对于那些重构效果非常差的样本而言是最好的异常分数。</p>
<h5 id="Data-preparation"><a href="#Data-preparation" class="headerlink" title="Data preparation"></a>Data preparation</h5><p>在预处理中，我们使用了基于Deep Complex U-Net的去噪网络对原始样本进行去噪[7,8]。该网络的主要前提是估计一个复杂的掩模并将其应用到谱图中。</p>
<p>该模型在训练时通过最小化干净样本和去噪样本之间的差异，以从有噪声的样本中提取干净的声音。为了减少背景工厂的声音，并使感兴趣的机器更响亮，为每一种机器类型训练了一个单独的模型。在每一种情况下，通过从AudioSet[9]中提取各种机械声音得到干净的样品。<strong>以其他机器类型的正常样本作为背景</strong>，与干净样本混合，得到有噪声的样本。这种方法的合理性是，假设不同的机器类型有完全不同的声音，因此当考虑去噪不同的机器时，包含工厂噪音和特定机器的声音的样本类似于背景噪音。</p>
<p>在训练过程中，保存在在不同信噪比值上的模型，以获得可用于不同级别去噪的去噪器。最终，每种机器类型有10种模型。单个模型包含2.6M参数。</p>
<h5 id="Model-architecture-and-ensembles"><a href="#Model-architecture-and-ensembles" class="headerlink" title="Model architecture and ensembles"></a>Model architecture and ensembles</h5><p>我们建立了几个模型，其架构和潜在空间维度略有变化。在每个模型中，编码器和解码器都有相同数量的隐藏层。编码器对潜在空间的每一维有两个输出。σ采用softplus函数，使其非负。解码器有两种不同的版本，估计$\hat \sigma$的方法不同。它要么通过一个双倍输出层(如编码器那样)估计，要么通过相同架构的单独网络(即所有层都是双倍的)。我们将第二种方法称为大精度(Big Precision, <strong>BP</strong>)。除输出层外，所有层均为RELU激活函数以及0.1的dropout。</p>
<p>我们在所有可用的样本(开发和额外的数据集)上为每种机器类型分别训练模型。使用OpenL3嵌入或log-mel功率谱将5个连续帧(如baseline)作为特征。每帧独立计算异常评分。我们尝试了以下基于帧的得分平均方法:</p>
<ul>
<li>mean</li>
<li>median</li>
<li>在一个3秒的窗口内计算中值后的平均值(winmed)</li>
<li>对于给定的机器类型，在所有帧上计算后限制最高在3个标准偏差内的平均值 (meancap)</li>
</ul>
<p>对所选模型的得分进行平均以实现最终的异常预测。</p>
<p><img src="http://picgo.southner.top/image-20211215153146389.png" alt="image-20211215153146389"></p>
<h4 id="ID-CONDITIONED-AUTO-ENCODER-IDCAE"><a href="#ID-CONDITIONED-AUTO-ENCODER-IDCAE" class="headerlink" title="ID CONDITIONED AUTO-ENCODER (IDCAE)"></a>ID CONDITIONED AUTO-ENCODER (IDCAE)</h4><p>在本节中，我们介绍ID条件自动编码器（IDCAE），它是针对开放集识别问题[11]设计的类条件自动编码器[10]的改编。</p>
<blockquote>
<p>[10] P. Oza and V. M. Patel, “<strong>C2ae: Class conditioned auto-encoder for open-set recognition</strong>,” in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.<br>[11] W. J. Scheirer, A. de Rezende Rocha, A. Sapkota, and T. E. Boult,“<strong>Toward open set recognition</strong>,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 7, pp. 1757–1772, 2013.</p>
</blockquote>
<h5 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h5><p>包含三个部分：</p>
<ul>
<li>Encoder E:$X-&gt;Z$,将特征向量$X$映射到潜在空间$Z$.</li>
<li>Decoder D:$Z-&gt;X$,将潜在向量$Z$映射至与特征向量相同大小的$D(Z)$</li>
<li>由两个函数$H_\gamma H_\beta$组成的调节器 conditioning：$\gamma -&gt; Z$,将来自$\gamma$的独热标签$l$映射至向量$H_\gamma(l) H_\beta(l)$,其与$Z$具有相同大小。</li>
</ul>
<p>向前传播时，code $Z$包含$H_\gamma(l) H_\beta(l)$，即$H(Z,l) &#x3D; H_\gamma(l)\cdot Z+ H_\beta(l) $,因此，整个系统有两个输入$X,l$,来自$X,\gamma$,输出$D(H(E(X),l))$。</p>
<p>给一个输入有特定ID的输入X，我们把对应这个ID的标签叫做match，其它标签叫做non-match。我们希望，当且仅当X是受匹配标签约束的正常样本时，我们的系统才能正常地重建X。异常的预测要么是重建太差，要么是样本有错误的ID。</p>
<p>给一批样本$X_1,X_2,…X_n$,其中**$\alpha$的样本有match，$1-\alpha$的样本为non-match**，$\alpha$为预定义。如果$l$为match，loss为系统输出和$X$的差：$||D(H(E(X),l))-X||$。如果$l$为non-match，loss为系统输出和常量矩阵$C$的差，$C$为与$X$有相同大小的常向量，即$||D(H(E(X),l))-C||$。$||\cdot||$为$L_1$或$L_2$范式。</p>
<p>在推理过程中，我们总是向网络提供匹配的标签。如果样本是非异常的，我们期望重建是正常的，从而产生较低的重建误差。如果样本异常，可能有两种情况。如果训练过程中的样本与任何样本都不一样，那么自动编码器将无法对其进行重建，从而导致较高的重建误差。然而，如果样本使人联想到来自其他ID的正常样本，则自动编码器将尝试重建向量C，从而再次导致高误差。</p>
<h5 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h5><p>输入归一化的log-mel图谱，1024 window,512 hop size,$log_{10}$,0均值单位方差。</p>
<p><img src="http://picgo.southner.top/image-20211216092853010.png" alt="image-20211216092853010"></p>
<p>使用默认参数的Adam优化器，每个机器，训练100个epoch，学习率以每5个epoch乘0.95的倍率缩减。每个epoch从图谱中随机采样300 frames。</p>
<h5 id="Submissions"><a href="#Submissions" class="headerlink" title="Submissions"></a>Submissions</h5><p>第一次提交：</p>
<p>超参数设置：$\alpha &#x3D; 0.75$(一批样本中有0.75的有正确的id)，C&#x3D;5(常矩阵)，F&#x3D;10，M&#x3D;128，使用平均绝对值误差。每个设置，有两个不同的实验，一个仅在develop数据集训练，一个在develop和additional数据集训练。后者效果好。</p>
<p>第二次提交：</p>
<p>为每种机器使用上面两种方法做一个集成。采用网格搜索，F&#x3D;10，$\alpha \in {0.9,0.75,0.5}$,$C \in {0,2.5,5,10}$,$M \in {128,256}$,采用均方误差和均绝对值误差。</p>
<p>两种集成方法：</p>
<ul>
<li>为每个机器类型选择使得AUC和pAUC均值最大的四个模型。</li>
<li>最大化平均异常分数。</li>
</ul>
<p>将输出作为最后整个系统的部分输入。</p>
<h4 id="KOSMIDER-SRPOL-TASK2-3-FREAK"><a href="#KOSMIDER-SRPOL-TASK2-3-FREAK" class="headerlink" title="KOSMIDER SRPOL TASK2 3 (FREAK)"></a>KOSMIDER SRPOL TASK2 3 (FREAK)</h4><p>其灵感来源于Wavenet[13],不过由时域转到了频域。使用神经网络从音频谱图预测下一帧。利用预测帧和实际帧来检测异常。</p>
<p>Freak模型结构如图所示：其中使用一维卷积，频带被视作channels，分成4组分别处理，这种方法被称为组卷积(grouped convolution)[14].</p>
<p><img src="http://picgo.southner.top/image-20211216154422560.png" alt="image-20211216154422560"></p>
<p>Residual block 使用类 wavenet 的架构，以一维causual卷积开始，然后是两个并行卷积（gate and value），相乘之后作最终卷积。图为 Figure 4 in WaveNet [13]。</p>
<blockquote>
<h5 id="WaveNet"><a href="#WaveNet" class="headerlink" title="WaveNet"></a>WaveNet</h5><p>WaveNet是谷歌DeepMind团队提出的自回归概率模型，其思想借鉴于PixelCNN在图像上的应用，即利用图像中先前生成的像素点来进行新像素点的生成。</p>
<p>文章提出，能不能把这种方法用于生成音频上，但音频采样率过高是一个挑战。</p>
<p>Wavenet模型可以根据一个序列的前 t-1 个点预测第 t 个点的结果，因此可以用来预测语音中的采样点数值。基本公式如下：</p>
<p><img src="http://picgo.southner.top/v2-c27bd5fc0270969c882799900b797237_r.jpg" alt="preview"></p>
<p>为了保证每一个时间步不会接收到未来时间步的信息，采用了casual convolution。</p>
<p><img src="http://picgo.southner.top/image-20211222203613251.png" alt="image-20211222203613251"></p>
<p>为了增大感受野，采用了多层空洞卷积，同时可以避免因卷积核过大而导致的参数量过多难以训练的问题。其中有两个重要的参数：</p>
<ol>
<li>Dilation：即输入数据间隔。</li>
<li>Kernel：核的多少，每次输入几个数，下图中kernel&#x3D;2。</li>
</ol>
<p><img src="http://picgo.southner.top/image-20211221163042281.png" alt="image-20211221163042281"></p>
<p>WaveNet生成语音的过程：</p>
<p><img src="http://picgo.southner.top/v2-c30c38e855aa24273739940a3ff411a1_b.webp"></p>
<h6 id="Wavenet整体网络结构如下："><a href="#Wavenet整体网络结构如下：" class="headerlink" title="Wavenet整体网络结构如下："></a>Wavenet整体网络结构如下：</h6><p><img src="http://picgo.southner.top/image-20211221164137096.png" alt="image-20211221164137096"></p>
<p>最下面是一个Conv1d的卷积层（1维卷积），然后是k层 Residual Block，其中t层输出是t-1层的输入，即如下图所示：</p>
<p><img src="http://picgo.southner.top/image-20211222204541579.png" alt="image-20211222204541579"></p>
<h6 id="两个门控单元"><a href="#两个门控单元" class="headerlink" title="两个门控单元"></a>两个门控单元</h6><p><img src="http://picgo.southner.top/image-20211222205742526.png" alt="image-20211222205742526"></p>
<p><img src="http://picgo.southner.top/image-20211222205713847.png" alt="image-20211222205713847"></p>
<p>$*$表示卷积操作，$\odot$表示对应位置相乘运算，k是层数索引，$f和k$表示过滤器和门，$W$是可学习卷积过滤器。</p>
<p>后面可添加额外条件。</p>
<p>文章声称在建模音频信号时这种激活函数的表现优于 ReLU。</p>
<h6 id="skip-connections"><a href="#skip-connections" class="headerlink" title="skip-connections"></a>skip-connections</h6></blockquote>
<p>*** ? channels 变化***</p>
<p>skip connection 的处理仅使用卷积，无normalization和activation。</p>
<p>在 Residual block 中，除casual卷积之外，其余卷积核都为1*1.</p>
<p>使用GroupNorm[15]，组数为1的GroupNorm可以等同于LayerNorm。每层卷积前都做normalization。</p>
<blockquote>
<p><img src="http://picgo.southner.top/image-20211216161133301.png" alt="image-20211216161133301"></p>
<p>N为样本轴，C为通道轴，H,W为每个通道的特征数量。</p>
<p><img src="http://picgo.southner.top/image-20211221104149869.png" alt="image-20211221104149869"></p>
<p><img src="http://picgo.southner.top/image-20211221104208094.png" alt="image-20211221104208094"></p>
</blockquote>
<p>无padding，因此谱图的前几帧无法预测。除最后一层外每层卷积后有activation。Sigmoid用于Gates，RELU用于其它情况。</p>
<p>最终提交的是一个模型集合，其中模型有不同的设置。每种设备类型都有4到14个模型。这些模型大多数有三层或四层，隐藏层的通道是输入谱图的<strong>5到6倍</strong>。使用STFT创建这些谱图，窗口为2048个采样点，跳长为512个采样点，然后转换为具有<strong>64或128个频率bins</strong>的mel谱图。算法被应用在这些谱图上，（value除外）。随后，使用来自训练数据集的统计数据对每个频率进行独立的标准化。所有模型都针对特定的设备类型进行训练，但同时使用该类型的所有可用机器。模型没有提供关于特定机器ID的任何信息。使用adam优化器，$\alpha&#x3D;0.001,\beta_1&#x3D;0.85,\beta_2&#x3D;0.999$.batchsize &#x3D; 32.</p>
<p>loss为均方误差。然而，预测分数的计算稍有差别。</p>
<p>第一种方法应用于valve和slider，首先针对每个频带计算第95 个百分位的均方误差（跨越时域），然后是这些结果的第95百分位（跨越频域）。</p>
<blockquote>
<p>第95百分位，即去掉最高的5%数据后的最大值。</p>
</blockquote>
<p>第二种方法依赖于预测与实际记录的振幅谱差的负对数概率。这种方法对对称噪声不太敏感。振幅谱的计算是基于随时间变化的平均谱图。使用威尔福德的在线算法[17]拟合的多元正态分布来估计概率。协方差矩阵要么是完整的（用于ToyCar），要么被限制为对角线（用于ToyConveyor）或identity（用于fan和pump）。</p>
<hr>
<blockquote>
<h5 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h5><p><em><strong>dilation conv</strong></em></p>
<p><img src="http://picgo.southner.top/v2-d552433faa8363df84c53b905443a556_720w.webp" alt="正常卷积"></p>
<p>​ 正常卷积</p>
<p><img src="http://picgo.southner.top/v2-4959201e816888c6648f2e78cccfd253_720w.webp" alt="Dilated Convolution with a 3 x 3 kernel and dilation rate 2"></p>
<p>​ Dilated Convolution with a 3 x 3 kernel and dilation rate 2</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://southner.top">southner</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://southner.top/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E2%80%94Daniluk/">http://southner.top/article/科研/论文阅读/2022/异音检测论文阅读—Daniluk/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://southner.top" target="_blank">南风er的小窝</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B/">异音检测</a></div><div class="post_share"><div class="social-share" data-image="http://picgo.southner.top/cover8.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E2%80%94gari/" title="异音检测论文阅读—Gari"><img class="cover" src="http://picgo.southner.top/cover6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-25</div><div class="title">异音检测论文阅读—Gari</div></div></a></div><div><a href="/article/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2022/%E5%BC%82%E9%9F%B3%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/" title="异音检测方法整理"><img class="cover" src="http://picgo.southner.top/cover10.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="title">异音检测方法整理</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Daniluk"><span class="toc-text">2.Daniluk</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Approach"><span class="toc-text">Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Heteroskedastic-Variational-Auto-encoders"><span class="toc-text">Heteroskedastic Variational Auto-encoders</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Model"><span class="toc-text">Model</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Data-preparation"><span class="toc-text">Data preparation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Model-architecture-and-ensembles"><span class="toc-text">Model architecture and ensembles</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ID-CONDITIONED-AUTO-ENCODER-IDCAE"><span class="toc-text">ID CONDITIONED AUTO-ENCODER (IDCAE)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Proposed-Method"><span class="toc-text">Proposed Method</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Model-Architecture"><span class="toc-text">Model Architecture</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Submissions"><span class="toc-text">Submissions</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KOSMIDER-SRPOL-TASK2-3-FREAK"><span class="toc-text">KOSMIDER SRPOL TASK2 3 (FREAK)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#WaveNet"><span class="toc-text">WaveNet</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Wavenet%E6%95%B4%E4%BD%93%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-text">Wavenet整体网络结构如下：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E9%97%A8%E6%8E%A7%E5%8D%95%E5%85%83"><span class="toc-text">两个门控单元</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#skip-connections"><span class="toc-text">skip-connections</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%A9%E5%B1%95"><span class="toc-text">扩展</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By southner</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="http://www.beian.miit.gov.cn/"><img class="icp-icon" src="https://pic3.zhimg.com/80/v2-d0289dc0a46fc5b15b3363ffa78cf6c7.png"><span>陕ICP备20012321号</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>