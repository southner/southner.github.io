<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读 | 南风er的小窝</title><meta name="keywords" content="mmwave雷达"><meta name="author" content="southner"><meta name="copyright" content="southner"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="0. Abstract在这项工作中，我们研究了如何使用反向散射的毫米波无线电信号来联合跟踪和识别在室内环境中移动的人的身份。我们建立了一个系统，可以有效地与多个人在同一室内空间共享和自由移动。这导致了一个复杂的设置，它需要处理所产生的(复合)反向散射信号的随机性和复杂性。所提出的系统结合了几个处理步骤:首先，对信号进行过滤，以去除非人类产生的伪像、反射和随机噪声。因此，执行基于密度的分类算法来分离">
<meta property="og:type" content="article">
<meta property="og:title" content="《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读">
<meta property="og:url" content="http://southner.top/2022/06/17/%E3%80%8AMultiperson-Continuous-Tracking-and-Identification-From-mm-Wave-Micro-Doppler-Signatures%E3%80%8B%E9%98%85%E8%AF%BB/">
<meta property="og:site_name" content="南风er的小窝">
<meta property="og:description" content="0. Abstract在这项工作中，我们研究了如何使用反向散射的毫米波无线电信号来联合跟踪和识别在室内环境中移动的人的身份。我们建立了一个系统，可以有效地与多个人在同一室内空间共享和自由移动。这导致了一个复杂的设置，它需要处理所产生的(复合)反向散射信号的随机性和复杂性。所提出的系统结合了几个处理步骤:首先，对信号进行过滤，以去除非人类产生的伪像、反射和随机噪声。因此，执行基于密度的分类算法来分离">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://picgo.southner.top/cover7.png">
<meta property="article:published_time" content="2022-06-17T04:57:39.000Z">
<meta property="article:modified_time" content="2022-06-17T04:57:56.659Z">
<meta property="article:author" content="southner">
<meta property="article:tag" content="mmwave雷达">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://picgo.southner.top/cover7.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://southner.top/2022/06/17/%E3%80%8AMultiperson-Continuous-Tracking-and-Identification-From-mm-Wave-Micro-Doppler-Signatures%E3%80%8B%E9%98%85%E8%AF%BB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: southner","link":"链接: ","source":"来源: 南风er的小窝","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-06-17 12:57:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/southner.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://picgo.southner.top/cover7.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南风er的小窝</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-17T04:57:39.000Z" title="发表于 2022-06-17 12:57:39">2022-06-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-17T04:57:56.659Z" title="更新于 2022-06-17 12:57:56">2022-06-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">17.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>54分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="《Multiperson Continuous Tracking and Identification From Mm-Wave Micro-Doppler Signatures》阅读"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0. Abstract"></a>0. Abstract</h2><p>在这项工作中，我们研究了如何使用反向散射的毫米波无线电信号来联合跟踪和识别在室内环境中移动的人的身份。我们建立了一个系统，可以有效地与多个人在同一室内空间共享和自由移动。这导致了一个复杂的设置，它需要处理所产生的(复合)反向散射信号的随机性和复杂性。所提出的系统结合了几个处理步骤:首先，对信号进行<strong>过滤</strong>，以去除非人类产生的伪像、反射和随机噪声。因此，执行基于密度的<strong>分类</strong>算法来分离不同用户的多普勒特征。最后的模块分别是基于卡尔曼滤波器和深度神经网络的<strong>轨迹跟踪和用户识别</strong>。我们的结果表明，最后提到的处理阶段的集成对于在多用户设置中实现鲁棒性和准确性是至关重要的。我们的技术在单目标公共数据集上进行了测试，其性能优于最先进的方法，并在我们自己的测量中进行了测试，这些测量是使用77  GHz雷达对同时在两种不同室内环境中运动的多个对象进行的。该系统以在线方式工作，允许以高达98%的准确度连续识别多个受试者，例如，四个受试者共享相同的物理空间，并且当用来自不属于模型学习阶段的具有挑战性的真实生活场景的看不见的数据进行测试时，准确度有小的降低。</p>
<h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>用于室内空间的  RADAR  设备最近引起了相当大的关注。它们通过发射无线电波并分析由环境反射并在其接收天线处收集的信号来工作。与摄像机监控系统相比，它们对光线不足的条件不敏感，并且更能保护隐私，因为没有收集场景的视频  [1]。与激光成像、探测和测距 (LIDAR) 等其他技术相比，雷达还具有能源效率 [2]。在这项工作中，我们提出了一个多人在线识别框架，该框架基于对毫米波  (mm-wave) 低功率调频连续波 (FMCW)  雷达接收到的（反射）信号的分析。我们的工作源于观察到，当对象在雷达附近行走时收集的反射信号是特定于人的，因为无线电反射取决于身体形状，并且及时取决于运动。因此，它们可用于识别在雷达设备附近移动的人的身份。我们的系统实现了高达  98%  的准确度，四个人在相对较小的室内空间内移动。这种性能以在线方式（连续跟踪和识别）实现，允许人们识别用户身份，因为它们共享相同的物理空间，而不依赖于场景的任何视觉表示。我们强调，之前的工作  [1]、[3]、[4]  已经解决了单人识别问题，而<strong>多用户案例仅通过叠加多个单人信号以离线方式解决</strong>。相比之下，我们构建了一个系统，当多人同时共享并在同一室内空间内自由移动时，该系统可以有效地工作，直接处理他们产生的复合反射信号。</p>
<p>为了区分不同人的行走方式（步态），我们分析了他们的<strong>微多普勒特征（μD）</strong>(micro-Doppler signature)，即由人体运动引起的小尺度多普勒效应。为了开发低复杂度的系统，我们首先提取 μD  特征，对从单个接收天线收集的信号执行距离多普勒 <strong>(RD) (range-Doppler)</strong>处理（即距离和速度）。之后，我们通过整合使用多个接收天线估计的接收无线电反射的到达角 (AoA) (the angle-of-arrival) 来解决所谓的距离多普勒方位角<strong>(RDA)</strong> <strong>(range-Doppler-azimuth )</strong>空间，从而解决 RD 处理的局限性。AoA 信息允许分辨与雷达设备距离相同且以相同速度移动的目标；这些目标在更简单的  RD 空间中几乎不可分离。</p>
<p>同时识别多个目标需要跟踪和分离对象（即它们对复合反向散射信号的贡献），以提取它们的  μD（时间）轨迹。我们的技术在 RD 或 RDA 空间中运行，通过以下步骤集成跟踪和识别：1）检测：去除随机噪声并应用基于密度的聚类算法（在 RD 或 RDA  地图上）进行目标检测，2 ) 跟踪：使用专用<strong>卡尔曼滤波</strong> (KF) 算法跟踪 RD (RDA) 空间中检测到的目标点，以及 3) 识别：利用深度卷积神经网络  (DCNN) 进行最终识别。我们强调，用户运动的联合估计（跟踪步骤 2）和识别特征的计算（步骤 3）是正确解开来自多个受试者的 RD/RDA  信号的关键。正如我们在第五节中通过实验验证的那样，跟踪错误和随之而来的错误识别严重依赖于这种联合处理。</p>
<p>在为识别目的处理雷达数据时，传播和反向散射现象的分析模型通常无法处理毫米波反射的高随机性和硬件非理想性。为了解决这个问题，我们利用了深度学习架构（即  DCNN），因为它支持数据驱动的系统训练。这种技术已成为此类处理任务的主导 [1]、[5]。</p>
<p>与之前的研究工作不同，所提出的框架是通过测量其在<strong>同时识别多个目标</strong>时的<strong>在线</strong>准确性来评估的，考虑到由于其他人的存在而导致的额外干扰、阻塞和杂散反射，并使用设计的实验重现目标跟踪的最坏情况。为此，我们模拟了现实生活中的场景，让拍摄对象在场景中自由行走，距离范围为  0 到 18 m。此外，我们<strong>在没有记录训练数据的房间中测试</strong>了所提出方法的通用性，即从模型学习的角度看不到这种环境。</p>
<p>接下来总结本文的主要贡献。</p>
<ul>
<li>我们提出了一种仅使用  RD 信息从步态的 μD 特征同时室内识别多个目标的系统，当三个受试者在同一物理环境中同时行走时，平均在线准确度达到 95%。我们为这种情况（RD  信号空间）设计的方法在室内环境中可以工作到长距离（18 m）。据我们所知，文献中没有其他研究为所考虑的多目标在线识别任务提出一个工作系统。</li>
<li>我们介绍了一种用于  μD 处理的新型 DCNN，并通过在公开可用的数据集 (IDRad [1]) 上对其进行评估，从而量化其相对于文献中提出的其他模型的性能改进，获得 90.69%  的准确度。</li>
<li>由于  DCNN  分类器提供的对主题身份的反馈，我们设计了一种新的跟踪方法，该方法对轨迹跟踪错误具有鲁棒性。我们的设计需要集成跟踪和识别模块，从而显着提高在线识别准确性。</li>
<li>我们展示了所提出的处理管道如何也可以应用于  RDA 数据，解决 RD 信号的一些限制。这允许以更高的计算复杂性和减小的检测范围为代价实现更高的目标检测能力。借助 RDA  信息，我们对四个受试者的在线准确率高达 98%。基于 RDA 的系统还在看不见的环境中进行评估，包括家具和静态物体，在两个受试者上达到 96%  的准确率。据我们所知，这是第一次针对毫米波雷达多目标跟踪和识别问题进行评估。</li>
</ul>
<p>本文的其余部分组织如下。在第二节中，对现有文献进行了回顾，强调了支撑我们方法的新颖方面。第三节详细介绍了  FMCW 雷达信号模型和 RD、RDA 图和 μD 特征的计算。第四节全面介绍了新框架。在第五节中，给出了实验结果，而在第六节中给出了结论性意见。</p>
<h2 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2. RELATED WORK"></a>2. RELATED WORK</h2><p>雷达传感器的人体识别是一个正在迅速发展的研究主题。一些文章针对使用无线电信号  [1]、[3]、[6]-[10] 从步态的 μD 特征对受试者<strong>身份进行分类</strong>。其他研究侧重于从用于安全或智能家居应用的反向散射无线电信号中<strong>识别人类活动</strong>  [5]、[11]、[12]。<strong>呼吸频率和心跳</strong>也可以被追踪，因为它们会引起受试者胸部可检测到的运动  [13]、[14]。由于本文的重点是<strong>步态识别和人物识别</strong>，下面我们简要回顾一下关于这个主题的最重要贡献。</p>
<p>曹等人 [6] 首次采用基于 DCNN AlexNet [15] 的分类器从她/他的步态 μD 特征中识别一个人，四个受试者的准确率达到约  97%。与我们的设置不同，他们的实验是在<strong>室外环境</strong>中进行的，其中来自静态物体的相关噪声反射通常很弱：室内环境中的墙壁在大多数情况下都非常接近感兴趣的目标，并且它们会导致噪声水平增加有用信号特征的提取要困难得多。</p>
<p>陈等人[9] 利用具有三个节点的多基地雷达和预训练的 DCNN 进行图像识别，以检测一个人是否携带武器或从两个对象识别人。杨等人 [7]  使用包括步行和跑步在内的六种不同运动的 μD 签名解决了识别问题。结果证明，跑步是最具辨别力的动作，对 15 名受试者提供了 95.21% 的识别准确率。在  [8] 中，使用放置在距雷达设备不同距离的跑步机，并训练 ResNet50 [16] 神经网络对 22 个受试者进行分类。</p>
<p>上述研究侧重于<strong>简化的实验场景</strong>，其中要求人在雷达设备的径向上沿直线行走。这种方法可以通过使步态特征更加明显来简化分类任务，但它不现实并且缺乏实际应用所需的通用性。在我们目前的工作中，我们专注于更现实的设置，让受试者在受监控的物理空间内以<strong>不受约束、自由</strong>的方式行走。</p>
<p>范德斯米森等人 [1] 在一个数据集上训练了一个 CNN  分类器，该数据集包含五个随机在两个不同房间中行走的受试者，以尝试实现更稳健的学习阶段。然而，每个对象都需要单独在房间里才能使系统工作，因为没有<strong>提供分离反向散射信号中不同目标贡献</strong>的方法。这严重限制了所提出算法对实际情况的适用性，其中多个目标可能共享并同时在物理空间中移动。同一作者还对他们的算法提出了两项改进，以提高其准确性，但仍然存在<strong>单目标限制</strong>  [3]、[10]。</p>
<p>执行多主体识别的第一次尝试可以在  [4] 中找到，其中使用<strong>通过 RDA 处理获得的 3-D 雷达点云</strong>代替 μD 签名，结合具有长短期记忆 (LSTM) 单元的循环神经网络用于后验识别。 12  名受试者的总体准确率约为 89%，并提供了系统能够区分两名受试者的证据。但是，当超过 2  名受试者共享相同的环境时，不进行准确性评估，并且在训练后不通过在不同的室内环境（例如，新房间）中测试分类器来评估分类器的通用性。当由于聚类过程中的失败而必须跟踪大量对象时，雷达点云数据的稀疏性可能会成为不准确的来源。迄今为止，还没有任何方法可以处理由于对象靠近而导致的信号簇叠加，从而将识别系统的工作范围限制在  3-5 m 的半径范围内。</p>
<p>在这项工作中，我们首先展示了仅使用  RD 信息识别多人的可行性，具有<strong>轻量级的处理工作流程</strong>和<strong>有限的硬件要求</strong>，从而改进了以前的研究。此外，我们扩展了所提出的系统以处理 RDA  数据，以防需要更高的检测性能，例如，处理更多目标，或者在 x - y  空间中寻求精确跟踪对象的情况。我们还展示了如何通过将识别输出反馈到用户的轨迹跟踪模块，结合这两个处理阶段来成功解决可靠地分离不同用户反射（尤其是在 RD  图像中）的复杂任务。我们的方法的改进和缺点被适当地量化和讨论。</p>
<h2 id="3-MM-WAVE-RADAR-SIGNAL-MODEL"><a href="#3-MM-WAVE-RADAR-SIGNAL-MODEL" class="headerlink" title="3. MM-WAVE RADAR SIGNAL MODEL"></a>3. MM-WAVE RADAR SIGNAL MODEL</h2><p>FMCW 雷达允许联合估计目标相对于雷达设备的距离和径向速度。这是通过发送chirp序列（即频率随时间变化的正弦波）并在接收器处测量反向散射信号的频移来实现的。</p>
<p>在本文中，我们使用线性调频连续波 (LFMCW) 雷达，其发射的chirp信号 (TX) 的频率在 T 秒内从基值 $f_o$ 线性增加到最大值$ f_1$。定义啁啾的带宽为  B = f1 - fo，带宽 B 和传输持续时间 T 通过 ζ = B/T 相关联，传输信号可表示为</p>
<p><img src="http://picgo.southner.top/image-20220505151637175.png" alt="image-20220505151637175"></p>
<p>chirps信号每$T_{rep}$秒发送一个，每次以P个chirp的序列发送，因此发送序列的总持续时间为$PT_{rep}$。在接收器处，混频器将接收信号  (RX) 与发射信号组合，生成中频 (IF) 信号，即瞬时频率为 T X 和 RX 信号频率之差的正弦波。每个chirp以采样周期  $T_s$（称为快速时间采样）进行采样，获得 N 个点，而 P 个样本，每个chirp来自相邻的chirp，以周期 Trep（慢时间采样）进行采样。</p>
<p>使用多输入多输出  (MIMO) 雷达设备允许额外估计反射的  AoA，方法是计算接收器天线元件之间由于它们的不同位置（即它们与目标的不同距离）而产生的相移。这称为空间采样，可以使用极坐标和笛卡尔坐标在物理空间中定位目标。在目前的工作中，我们采用线性接收天线阵列，即  RX 天线沿单个维度对齐，并间隔距离 $δ$。</p>
<h3 id="A-Range-Doppler-and-Azimuth-Information"><a href="#A-Range-Doppler-and-Azimuth-Information" class="headerlink" title="A. Range, Doppler and Azimuth Information"></a>A. Range, Doppler and Azimuth Information</h3><p>发射的信号在某个空间点撞击目标，产生可在接收器处检测到的反向散射信号。该反射信号等于具有延迟  $\tau$ 的发射波形，该延迟 $\tau$ 取决于目标和雷达之间的距离、它们的相对径向速度以及由于接收天线元件的不同位置而导致的额外距离。考虑到最常见的情况，其中 Q  目标存在于雷达照射范围内，L 个天线在线性接收器阵列上可用，并用 c 表示光速，让 $R_q$、$v_q$ 和$ θ_q$ 分别为距离、速度、和相对于目标 q  的设备的方位角，在第$l$天线处测量的来自目标 q 的信号反射的延迟可以计算为</p>
<p><img src="http://picgo.southner.top/image-20220505152034274.png" alt="image-20220505152034274"></p>
<p>混合采样后的中频信号表示为</p>
<p><img src="http://picgo.southner.top/image-20220505152310020.png" alt="image-20220505152310020"></p>
<p>其中  $α_q$ 是一个系数，它考虑了由于目标的天线增益、路径损耗和雷达横截面 (RCS) 而导致的衰减效应，$w $是高斯噪声项。相位 $\phi q(n, p, \iota)$  取决于目标、快时间、慢时间和空间采样指数。通过忽略贡献很小的项，其近似表达式可以通过引入量$ f_{d_{p} }= 2 f_ov_q/c 和 f_{d_{p} } = 2ζ Rq/c $ 来编写，它们分别表示从q反射的信号的多普勒频率和beat frequency。</p>
<p><img src="http://picgo.southner.top/image-20220511093421572.png" alt="image-20220511093421572"></p>
<h3 id="B-μ-Doppler-Map"><a href="#B-μ-Doppler-Map" class="headerlink" title="B. μ-Doppler Map"></a>B. μ-Doppler Map</h3><h2 id="4-PROPOSED-ALGORITHM"><a href="#4-PROPOSED-ALGORITHM" class="headerlink" title="4.PROPOSED ALGORITHM"></a>4.PROPOSED ALGORITHM</h2><p>在本节中，我们提供了所提出算法的一般概述。此处介绍的块用于  RD 和 RDA 处理，由于两个映射的不同属性，每个算法的实现细节略有不同。</p>
<h3 id="A-Overview-of-the-Signal-Processing-Pipeline"><a href="#A-Overview-of-the-Signal-Processing-Pipeline" class="headerlink" title="A. Overview of the Signal Processing Pipeline"></a>A. Overview of the Signal Processing Pipeline</h3><p>从  μD 频谱图中提取步态特征可能非常困难，并且结果受环境和硬件不理想的影响很大。此外，在多个目标的情况下，μD  是由所有移动实体的叠加贡献产生的复合时间信号。这些贡献的分离非常困难，而在 RD 或 RDA 空间中则更容易，因为来自不同用户的反射被用户与雷达 (RD)  的距离或他们的距离和到达角（ RDA）进一步隔开，产生如图1所示的点云。因此，我们的动态处理框架通过以下步骤在RD或RDA空间上工作（见图2）：</p>
<p><img src="http://picgo.southner.top/image-20220509222529356.png" alt="image-20220509222529356"></p>
<ol>
<li><p><strong>Detection</strong>: 首先，对雷达混频器输出的原始数据应用预处理步骤，以<strong>去除静态反射和噪声</strong>（参见第  IV-C 节）。然后，执行来自“用于噪声应用的基于密度的空间聚类”（DBSCAN）算法家族的聚类方案，以将来自<strong>不同主体的 RD/RDA  贡献与复合信号分开</strong>（参见第 IV-D 节）。</p>
</li>
<li><p><strong>Tracking</strong>: 应用在后续 RD 或 RDA 帧上运行的卡尔曼滤波器以获得对真实对象状态的可靠估计（即，其<strong>位置</strong>，参见第 IV-E  节）。使用匈牙利算法执行在当前<strong>时间范围</strong>内检测到的 RD/RDA 集群与正确用户轨迹的关联（参见第 IV-F 节）。</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/39912633">https://zhuanlan.zhihu.com/p/39912633</a></p>
<p>一种优化估算算法，在不确定和间接测量的情况下估算系统状态。</p>
</blockquote>
</li>
<li><p><strong>Identification</strong>: 特征提取和用户识别是使用基于初始块  (IB) 的 DCNN 模型执行的，该模型将每个对象的 μD 频谱图的输入部分（在使用 DBSCAN 和轨迹跟踪后从对象的 RD/RDA 数据中获得）  ）。如果跟踪失败并且某些主体的 RD/RDA 集群无法分离，则 DCNN 输出用于通过将身份信息反馈给轨迹跟踪块来重新建立目标的正确标记（详见第 IV-J  节）。</p>
</li>
</ol>
<p>从反向散射的毫米波信号中进行多人识别提出了几个<strong><em>挑战</em></strong>。首先，由于毫米波室内传播环境的高度<strong>随机性</strong>，很难实现对不同目标的有效和可靠分离。其次，基于  μD 签名的稳健分类需要 DCNN  身份分类器的<strong>高泛化能力</strong>。事实上，我们试图从他们的移动方式区分开被试者，而不是从可能不太针对个人的属性（例如他们的平均步行速度）区分开来。所提出方法的一个显着和关键特征是<strong>轨迹跟踪和识别的动态集成</strong>，它允许根据识别块的输出来纠正轨迹跟踪错误。因此，我们的系统适用于在线处理，对  RD/RDA 空间中用户集群的叠加、可变步行速度、由于物体/表面反射造成的假目标、分类不稳定性和目标出现（消失）的场景。</p>
<h3 id="B-Notation"><a href="#B-Notation" class="headerlink" title="B. Notation"></a>B. Notation</h3><p>系统以离散时间增量运行，t  = 1, 2,  . . , T ，其中时间步长有固定的持续时长$\Delta t$ 秒，对应于雷达帧周期。在其余部分中，算法的顺序演变可以互换地用<strong>时间步长</strong>和雷达帧来表示。在当前时间步  t 中检测到的 <strong>RD/RDA 簇</strong>用索引 $d = 0, 1,  . . , D_{t - 1} 和 D_t $ 进行标记。类似地，当前由<strong>轨迹跟踪块</strong>维护的 $K_t$ 轨迹使用变量 k = 0, 1, … , Kt − 1进行索引。我们用 U  表示<strong>训练系统的类（身份）</strong>的数量，即，将被识别为已知的身份，通过索引 u = 0, 1,  . . , U. 表示。粗体字，大写字母表示矩阵，例如 X，带有元素  Xij，而粗体小写字母表示向量，例如 x。符号⊗表示矩阵之间的克罗内克积，X−1 表示矩阵 X 的逆矩阵，$x^T$ 表示向量 x 的转置。 N (μ,  σ 2) 表示具有均值 μ 和方差 σ 2 的高斯随机变量。</p>
<h3 id="C-Preprocessing"><a href="#C-Preprocessing" class="headerlink" title="C. Preprocessing"></a>C. Preprocessing</h3><p>预处理涉及两个不同的阶段，即去除静态反射和去噪。</p>
<ol>
<li><em>Removal of Static Reflections</em>:这是处理管道中的第一个块：它接收原始雷达数据作为输入，即包含雷达在每个时间步输出的  3-D 信号 [参见 (3)] 的雷达立方体。如第 III-A 节所述，将 DFT 应用于此信号以获得 RD 或 RDA 图。在 <strong>RD  情况</strong>下，仅收集一个通道（一个接收天线），首先沿距离维度应用 DFT，然后沿多普勒维度应用 DFT，从而生成包含目标的距离和多普勒信息的矩阵。在 <strong>RDA  处理情况</strong>下，计算沿角度维度的附加 DFT。在 DFT 之前，<strong>沿每个维度应用汉宁窗</strong>。 RD 和 RDA  映射经过进一步处理，以消除静态目标的反射。由于固定对象被映射到对应于 0 m/s 速度值的垂直线，我们通过从 RD 和 RDA  图中切割与可忽略的速度相关的多普勒通道来消除它们的贡献。此处理步骤至关重要，因为如果不去除静态杂波，其将在RDA  地图占主导地位，导致来自对象的反射与静态贡献合并，从而导致跟踪过程中的严重困难。作为一个额外的好处，该算法变得更少依赖于环境特征。</li>
<li>Denoising:去噪分两个阶段应用。在第一阶段，沿<strong>距离维度</strong>应用接收功率阈值，仅保留高于其的信号值。随着范围的增加，阈值在对数域中线性降低，从最小范围的  -97 dBm 到最大范围的 -107 dBm。这是因为距离雷达设备较远的目标会受到使用固定阈值的惩罚，因为它们接收到的功率较小。在 RDA  处理的情况下，沿<strong>角度维度</strong>应用进一步的阈值，丢弃接收功率电平相对于峰值弱于 15 dB 的角度区间。这是为了减轻波束成形过程产生的旁瓣的影响。生成的数据点代表  2-D (RD) 或 3-D (RDA) 图中的位置，其中接收到足够高的反射功率。这些点代表来自目标的候选反射。</li>
</ol>
<h3 id="D-Target-Clustering-in-RD-RDA-Spaces–DBSCAN"><a href="#D-Target-Clustering-in-RD-RDA-Spaces–DBSCAN" class="headerlink" title="D. Target Clustering in RD/RDA Spaces–DBSCAN"></a>D. Target Clustering in RD/RDA Spaces–DBSCAN</h3><p><strong>基于密度的聚类</strong>与基于距离的聚类相反，它根据输入样本的密度对输入样本进行分组。属于这一类的最广泛使用的算法之一是  DBSCAN [20]，它以前已在 [21] 和 [4]  中用于聚类雷达点云。该算法对所有数据点进行顺序扫描，扩展一个集群，直到不再满足某个密度条件。它需要指定两个输入参数，$\varepsilon ,m_{pts}$，分别表示每个点周围的半径和其中满足密度条件的其他点的最小数量。在这项工作中，我们使用 $\varepsilon$= 0.04 和$ m_{pts}$ =  40。雷达图的每个点在去噪后都映射到坐标矢量$p_i = [r_i, v_i ]^T$（距离和速度）以进行 <strong>RD</strong> 处理，并且$ p_i = [ r_i , v_i , θ_i]^T  $（范围、速度和角度）用于 <strong>RDA</strong> 处理，以及相关的接收功率 $P_{RX}(p_i )$。为了简化距离阈值参数的选择，在实际聚类步骤之前，将点 $ p_i $的范围、角度和速度坐标在区间 [0, 1] 内<strong>归一化</strong>。 DBSCAN 应用于归一化的点集：一些具有低密度的点被分类为噪声并被丢弃，而其余点的一个分区<strong>在每个时间步  t 输出</strong>。我们用 $C_0, C_1,  . . , C_{D_{t }-1}$ 来表示得到的簇，每个 Dt  检测一个。在聚类操作之后，点云被重新映射到原始值范围。对于每个集群，我们选择其质心作为人的真实坐标（RD 的范围和速度，RDA  的范围、速度和角度）的噪声观察。<strong>质心</strong> $z_d$, d = 0, 1, . . . , $D_{t} − 1$  是通过用相应的<strong>归一化反射功率值</strong>对每个聚类点进行加权来计算的，即</p>
<p><img src="http://picgo.southner.top/image-20220510100236224.png" alt="image-20220510100236224"></p>
<p>通过这种方式，质心倾向于那些具有更高功率的点，在表示实际目标位置时赋予它们更多的重要性。请注意，DBSCAN  聚类<strong>仅通过对当前时间步进行操作</strong>来执行聚类检测，即不考虑先前时间步中的点。虽然这是可取的，因为它会导致<strong>低复杂度</strong>的聚类算法，但它也存在一些缺点。事实上，并非在任何特定时间步长中检测到的所有聚类都可以代表实际对象，但噪声反射和鬼目标经常（随机）出现在  RD/RDA 空间中。当它们的功率与实际目标反射的功率相当时，DBSCAN  可以将它们注册到检测到的集群中。为了弥补这一点，我们使用了<strong>进一步的跟踪程序</strong>，在下面的第 IV-E 节中进行了描述，该程序分析了 RD/RDA  空间中集群在后续帧中的移动。这允许<strong>检测和移除虚假集群</strong>，因为它们可能会在随机时间出现（并在不久之后消失），而实际目标生成的集群往往会跨帧持续存在。</p>
<h3 id="E-Trajectory-Tracking–Kalman-Filter"><a href="#E-Trajectory-Tracking–Kalman-Filter" class="headerlink" title="E. Trajectory Tracking–Kalman Filter"></a>E. Trajectory Tracking–Kalman Filter</h3><p>轨迹跟踪是通过对目标的过去位置应用<strong>离散卡尔曼滤波器</strong> (KF) 来执行的，这些位置由簇质心 $z_0 。 . . , z_{D_t  -1}$表示。注意，由于<strong>聚类过程中的错误或受试者进入或离开受监控环境</strong>，在时间步 t 开始时保持的轨迹数 Kt-1 可能与 DBSCAN 检测到的集群数 Dt  不同。这些事实需要通过<strong>专门的策略</strong>仔细处理，详见第 IV-F 节。接下来，针对单个轨迹提出了 <strong>KF  跟踪过程</strong>，但同样的过程并行应用于每个轨迹。此外，为了提高清晰度，RD 和 RDA 处理案例被分开处理。</p>
<ol>
<li>RD  系统模型：KF 模型将目标的实际距离（距雷达设备）和速度 联系起来<strong>$x_t = [r_t, v_t ]……T$</strong> （即隐藏系统状态）到质心值 <strong>$z_t$</strong> （即噪声) 观察。运动模型由两个矩阵  F 和 H 定义。F 是<strong>转移矩阵</strong>，将当前时间步 xt 中的系统状态与 xt-1 相关联，而 H 是<strong>观察矩阵</strong>，将 $z_t $与 $x_t$ 相关联。将 ut 和 rt  分别称为过程噪声和观测噪声，得到系统的动态模型如下：</li>
</ol>
<p><img src="http://picgo.southner.top/image-20220510140444537.png" alt="image-20220510140444537"></p>
<p>假设一个<strong>恒定速度模型</strong>，<strong>过渡和观察矩阵</strong>是</p>
<p><img src="http://picgo.southner.top/image-20220510140503919.png" alt="image-20220510140503919"></p>
<p>$I_2$是一个2<em>2的单位矩阵，我们假设<em>*过程噪声</em></em> $u_t$ 是由随机加速度$a_t$引起的,加速度遵循0 均值和方差 $σ ^2_a$的高斯分布——$a_t ∼<br>N (0, σ^ 2_a )$,即</p>
<p><img src="http://picgo.southner.top/image-20220510141304338.png" alt="image-20220510141304338"></p>
<p><strong>过程噪声协方差矩阵</strong>计算为</p>
<p><img src="http://picgo.southner.top/image-20220510141416098.png" alt="image-20220510141416098"></p>
<p>而<strong>观测噪声协方差矩阵</strong>是</p>
<p><img src="http://picgo.southner.top/image-20220510141437787.png" alt="image-20220510141437787"></p>
<p>$σ_a、σ_r、σ_v$ 的合适值难以解析计算。在这项工作中，我们根据实验观察经验确定它们，得到 $σ_a$ = 0.6 m / s2，$σ_r $= 0.1 m,$σ_v $= 0.5 m / s</p>
<p>为雷达接收到的<strong>第一帧中每个检测到的簇</strong>初始化一个新的  KF 模型。在连续帧中，轨迹通过 KF 预测-更新步骤来维护，计算状态 $\hat x_t$ 和状态协方差矩阵 $\hat P_t $的估计值，从中推导出状态的估计后验分布为  $\hat p(x_t|z_1, … , z_t) = N ( \hat x_t , \hat P_t)$ [22]。</p>
<ol>
<li>RDA  系统模型：在 RDA 情况下，<strong>仅使用对距离和方位角的观测</strong>来执行跟踪，因为在模型中引入径向速度会导致系统变得过于非线性而无法使用 KF  获得可靠的估计。具体来说，观测向量 zt 包含目标的范围和角位置，$z_t = [r_t, θ_t ]^T$。系统状态定义为 <strong>$x_t = [x, v_x, y, v_y]T$</strong>  ，其中 x 和 y 是目标笛卡尔坐标，$v_x 和 v_y $是沿两个轴的速度。得到的非线性模型是</li>
</ol>
<p><img src="http://picgo.southner.top/image-20220510153441895.png" alt="image-20220510153441895"></p>
<p><img src="http://picgo.southner.top/image-20220510153706455.png" alt="image-20220510153706455"></p>
<p>为了处理  (18) 中的非线性，在接收到一个新的观测值$ z_t $时，我们计算一个<strong>变换后的观测向量</strong>$ z’_t = [r_t cos θ_t, r_t sin θ_t]^T$ 。 使用$z’$，模型变为线性，如（9），（10），具有矩阵</p>
<p><img src="http://picgo.southner.top/image-20220510153852074.png" alt="image-20220510153852074"></p>
<p>过程和观察噪声的协方差矩阵是</p>
<p><img src="http://picgo.southner.top/image-20220510154034592.png" alt="image-20220510154034592"></p>
<p>同样，很难直接计算噪声方差，因此我们使用  [21] 中提出的人类受试者的经验值：$σ_a$ = 8 m / s2，$σ_x = σ_y$= 0.5 m/ s2,。由于使用了变换（极坐标），预测和更新步骤的线性方程与  RD 处理情况下的线性 KF 相同。</p>
<p>我们使用的恒速模型提供了人类步行目标运动的良好近似值：运动速度约为  1 m/s，帧速率为 15 fps，KF 能够可靠地跟踪目标。</p>
<h3 id="F-Matching-Trajectories-to-Clusters–Hungarian-Algorithm"><a href="#F-Matching-Trajectories-to-Clusters–Hungarian-Algorithm" class="headerlink" title="F . Matching Trajectories to Clusters–Hungarian Algorithm"></a>F . Matching Trajectories to Clusters–Hungarian Algorithm</h3><blockquote>
<p><strong>匈牙利算法</strong>是一种在<a href="https://zh.m.wikipedia.org/wiki/时间复杂度">多项式时间</a>内求解<a href="https://zh.m.wikipedia.org/wiki/任务分配问题">任务分配问题</a>的<a href="https://zh.m.wikipedia.org/wiki/组合优化">组合优化</a><a href="https://zh.m.wikipedia.org/wiki/算法">算法</a></p>
</blockquote>
<p>为了将轨迹与集群匹配，我们使用基于<strong>最近邻标准过滤器</strong>  (NNSF) 的方法。在每一帧，我们必须将 $D_t$ 新聚类检测与 $K_{t-1} $先前的轨迹相关联，这是一个<strong>组合问题</strong>。该过程包括两个步骤，首先我们计算一个$ K_{t-1} ×  D_t$ 成本矩阵 J，它将时间步 (t-1) 的轨迹与时间步 t 的聚类检测相关联。 J 的每个元素$ J_{ij} $编码了将轨迹 i 与聚类检测 j 相关联的成本。鉴于  RD 和 RDA 数据的属性略有不同，我们发现成本函数的最佳选择在两种情况下有所不同，如下所述。</p>
<ol>
<li>RD Cost Matrix: 在  RD 情况下，我们从每个目标状态$x_i$ 定义一个框 $B_i$ 来包含主体反射，以状态为中心并具有固定尺寸$ h_ B$ 和  $w_B$。我们假设，考虑到相对于对象速度的高帧速率，在随后的两个帧中，具有来自给定目标的反射的框应该在前一个时间步与她/他的框显着重叠。让$ B_i $和 $B _j  $分别表示在上一个时间步 (t-1) 与轨迹 i 相关联的集群的框和在当前时间步 t 与新目标检测 j 相关联的框，以 $z_ j $为中心.轨迹 i 和新检测到的集群  j 之间的<strong>关联成本</strong>通过负交叉联合 (IOU) 得分计算，定义为    </li>
</ol>
<p><img src="http://picgo.southner.top/image-20220511085534276.png" alt="image-20220511085534276"></p>
<p>支持这一点的想法是，两个框重叠得越多，它们就越有可能代表两个集群，其中包含来自同一目标用户的反射信号分量，当她/他从  (t - 1) 移动到 t。</p>
<ol>
<li><p>RDA Cost Matrix:在  RDA 的情况下，成本矩阵元素定义为从轨迹状态预测的观测值与真实观测值（检测）之间的平方马氏距离</p>
<p><img src="http://picgo.southner.top/image-20220511085906965.png" alt="image-20220511085906965"></p>
<p><img src="http://picgo.southner.top/image-20220511085923285.png" alt="image-20220511085923285"></p>
</li>
</ol>
<p>为  RD 和 RDA 处理选择两种不同的评分函数是由这两种情况下雷达图的不同属性推动的。在 RDA  空间中，轨迹跟踪使用<strong>距离和角度信息，从而导致围绕质心的紧凑集群</strong>。相反，在 RD 空间中使用的速度信息导致沿着该维度的稀疏簇，IOU 分数允许人们通过 h B 和  wB 控制盒子形状，即它的形状因子，以避免沿速度轴的叠加重量小于沿距离轴的叠加重量。这显着减轻了由于 RD 空间中的集群稀疏性导致的跟踪错误。</p>
<p>给定成本矩阵，匈牙利算法  [23] 用于有效地获得产生最低总成本的关联，复杂度为$ O((K_{t−1} D_t )^3)$。该算法使用成本矩阵作为输入，并将每个轨迹与仅一个聚类检测配对。</p>
<h3 id="G-Trajectory-Management"><a href="#G-Trajectory-Management" class="headerlink" title="G. Trajectory Management"></a>G. Trajectory Management</h3><p>在轨迹跟踪期间，我们必须处理 1）未检测到的轨迹和新的聚类检测（即非方阵 J 的情况）； 2）由于漏检导致的轨迹不稳定； 3)  <strong>金属物体反射产生的幽灵目标的存在</strong>。为了解决这些问题，我们构思了以下轨迹管理措施。</p>
<ol>
<li>不匹配的轨迹（RD  和 RDA）：与任何当前集群检测无关的轨迹被标记为未检测到，并在被删除之前保持 max_age = 10 帧。在这些帧期间，它们的状态使用 (9)  更新。与任何现有轨迹无关的聚类检测称为不匹配，如果在 min_det = 15 个连续帧中检测到它们，则将其初始化为新轨迹。</li>
</ol>
<p>这种机制使系统对随机出现在环境中和从环境中消失的对象具有鲁棒性，并且可以根据需要以可承受的延迟创建或删除其轨迹。我们强调，主体反射可能因任何原因未被检测到、随后被删除和重新初始化，例如，由于测量序列开始时的阻塞，更一般地说，被监控序列的任何点阻塞，或由于目标移动进出现场。这些暂时的影响不会影响对所提议系统的正确跟踪，一旦获得可靠的测量结果，其轨迹将不断改进和重新初始化。</p>
<ol>
<li>改善轨迹不稳定性  (RDA)：由于漏检导致的轨迹不稳定性和合并轨迹是 RDA  案例中的一个问题，其中杂波更为严重。出于这个原因，我们在每个轨迹周围引入了一个选通区域，即，如果在时间步 t 的关联成本（平方马氏距离）高于由 γ  表示的阈值，则检测永远不会与轨迹相关联。此操作丢弃轨迹和位于椭圆形区域之外的聚类之间的所有可能关联，椭圆形区域的形状和大小由创新协方差 St 和阈值 γ  决定，通常根据逆 χ 的所需置信水平选择 w h i c h具有 2 个自由度的 2 分布 [24]。在这项工作中，我们使用 90% 的置信度，这导致 γ =  4.605。</li>
<li>处理合并轨迹  (RDA)：通过检查估计状态之间的欧几里德距离来检测合并轨迹。如果两个轨迹之间的距离小于最小距离 dmin = 0.5 m，则删除最后 5  个状态估计中方差最大的轨迹，以利于稳定性。</li>
<li>去除“幽灵”目标（RDA）：作为最后的轨迹管理措施，我们消除了估计状态位于房间边界之外的所有轨迹。由于金属物体和宽平面上的多径反射，这对消除鬼影目标具有显着的积极作用。这些不需要的反射通常与来自真实对象的直接反射非常相似，但出现在不同的角度位置，并且由于信号遵循的路径更长，因此距离更远。在这项工作中用于去除幽灵目标的方法使用了一些关于房间尺寸的先验信息。在实践中，粗略的知识就足够了，沿  x 和 y 参考轴的房间尺寸就足够了。这些数据可以像我们一样从平面测量中获得，也可以通过对雷达信号进行的一些预处理获得。后一种方法留作未来的研究工作。</li>
</ol>
<h3 id="H-Computation-of-μD-Time-Series"><a href="#H-Computation-of-μD-Time-Series" class="headerlink" title="H. Computation of μD Time Series"></a>H. Computation of μD Time Series</h3><p>通过选择属于当前与她/他的轨迹相关联的集群的那些点来计算每个目标的  μD 签名。这允许为每个主题获得单独的签名。此类签名被输入到基于 DCNN 的分类器中以执行识别，请参见第 IV-I 节。对于给定时间步长中 μD  矢量的计算，累积范围 (RD) 或范围和角度 (RDA) 维度上的接收功率，产生维度等于所考虑的多普勒 bin 数量 $n_{chn}$  的向量。因此，这些向量随时间堆叠并作为频谱图传递给 DCNN 分类器。该图像是以下标识块的输入 X，参见第 IV-I 节。</p>
<h3 id="I-Identification–DCNN"><a href="#I-Identification–DCNN" class="headerlink" title="I. Identification–DCNN"></a>I. Identification–DCNN</h3><p>所提出的分类器架构是  DCNN。当输入数据表现出空间结构时，这种神经网络适用于分类和特征提取，例如在图像处理应用中。 DCNN  的主要组件是卷积层，其中输入与学习权重的过滤器（或内核）进行卷积，以识别某些模式，组织成所谓的特征图，随着层的深度。 DCNN  在过去几年中被广泛用于频谱图数据中的特征提取，例如，在语音识别和音频处理应用中 [25]。</p>
<p>所提出的  DCNN 基于初始和残差网络结构，这两种架构通常用于最先进的图像分类任务。 IB 是为不同尺度的复杂特征提取而开发的 DCNN 结构，在 DCNN  的每一层以并行方式使用不同的内核大小，并连接得到的特征图 [26]。在我们的例子中，每层使用 1 × 1、3 × 3 和 5 × 5 内核过滤器，以提取 μD  签名的小规模和大规模特征。单个 IB 的有效实现如图 4 所示：顶部分支使用 1 × 1 卷积，提取小尺度特征，顶部的以下两个分支使用 3 × 3 和 5 ×  5 卷积，前面是 1 × 1 卷积以降低其复杂度，即特征图的数量，并防止参数数量变得过大。底部分支执行 3 × 3  最大池化操作，仍然提取小规模特征，但从输入的下采样表示中提取。</p>
<p><img src="http://picgo.southner.top/image-20220511093440463.png" alt="image-20220511093440463"></p>
<p><img src="http://picgo.southner.top/image-20220511093502864.png" alt="image-20220511093502864"></p>
<p>残差网络依赖于卷积块[16]的输入和输出之间的跳跃连接，以使网络学习数据相对于输入的残差表示。这已被证明可以更快地训练更深层次的网络并获得显着的性能提升。在我们的例子中，跳过连接放置在每个  IB 的输入和输出之间，对各自的张量求和。对每个跳过连接应用 1×1 卷积以调整特征图的数量，使其与输出匹配。</p>
<p>输入信号 X 是 $Wc$ = 30 帧 $μD$ 矢量的序列，对应于每个受试者的 $WcT_{seq}$ = 2 s 测量时间。选择的多普勒 bin 数量为 $n_{chn}$ =  200（有关评估设置的详细说明，请参见第 V 节），因此输入图像的尺寸为 200 × 30。输入 X 通过组成 DCNN  的三个块，即，一个编码器，一个解码器，一个全连接（FC）网络。编码器网络 E 由四个堆叠的 IB 组成，输出特征图的数量分别等于 16、32、64 和  16；这些块由 2 × 2 最大池化层分隔，这些池化层执行降维。</p>
<p>编码器的扁平化输出 c 是具有较低维度的输入的潜在表示，即一个code，被馈送到解码器和 FC 网络.</p>
<ol>
<li>解码器网络 D 学习重建输入图像。 D 是一个有四层的 CNN，每层有 3×3 个滤波器，特征图的数量分别等于 32、32、16 和 1。在每次卷积之前进行  2×2 的上采样步骤。输入的重建副本称为 $ \hat X$。分类器的这个分支不直接对分类结果做出贡献，但它在训练阶段用于指导网络提取有意义的特征，充当<strong>正则化器</strong>。据我们所知，对这类问题使用解码器网络是我们设计的原创性贡献。我们发现它的使用是有效的，导致测试集中的准确度提高了  2%–3%。</li>
<li>FC  网络$ F$ 使用一个 U 维向量输出一个U维编码，其中包含输入属于每个类的概率，即$ \hat y = [ \hat y_1, . . . ,  y_u ]^T , \hat y_u  ∈ [0, 1] $,$ \sum _u \hat y_u = 1$。该网络由一个具有 128 个神经元的隐藏层组成。指数线性单元 (ELU) 激活函数 [27]  将输入连接到隐藏层神经元，而 SoftMax 层用于计算 U 输出概率。</li>
</ol>
<p>以下等式形式化了编码器、解码器和  FC 块的输入-输出关系：</p>
<p><img src="http://picgo.southner.top/image-20220511094506766.png" alt="image-20220511094506766"></p>
<p>全架构的损失函数是解码器损失函数的加权和，它衡量的是原始输入图像  X 和重建的 X 之间的差异，以及 FC 分支（分类）的损失。对于前者，我们选择<strong>平均每像素</strong>二进制交叉熵损失，而预测和真实标签 y  之间的分类交叉熵损失用于后者。我们将$ n_X = n_{chn}W_c$ 称为 μD 输入图像中的元素数，U 称为类数（已知的用户身份），$α_{rec} $ 是加权因子。输入图像和重建图像的第 p 个像素，其值为 [0, 1]，分别用 $X _p 和 \hat X_ p $表示，总加权损失函数为</p>
<p><img src="http://picgo.southner.top/image-20220511095223727.png" alt="image-20220511095223727"></p>
<p>图  3 显示了分类器的完整结构。作为正则化措施，在编码器和 FC 分支的每一层之后，我们应用批量归一化 [28]。网络中的所有隐藏节点都使用 ELU 激活函数  [27]。完整的神经网络有 560 819 个可调参数（网络大小）。</p>
<h3 id="J-Labeling-and-Trajectory-Correction-Procedure"><a href="#J-Labeling-and-Trajectory-Correction-Procedure" class="headerlink" title="J. Labeling and Trajectory Correction Procedure"></a>J. Labeling and Trajectory Correction Procedure</h3><p><strong>以前</strong>从毫米波获得轨迹的人类识别方法依赖于唯一的  KF 输出，用于整个运动，并在接下来的步骤中，使用例如某种神经网络 [4] 对预先计算的轨迹进行分类。现在，考虑两个用户 1 和 2  的轨迹，它们在某个时间点在所考虑的 RD/RDA 空间中相交。此时，<strong>无法区分这两个用户，因为他们的集群在很大程度上重叠</strong>，并且从他们的集群分开的那一刻起，KF  再次跟踪轨迹。然而，目标关联过程可能会错误地将轨迹与检测关联起来，即将轨迹 1 分配给用户  2，反之亦然。这个问题很难用以前的算法纠正，而用我们设计的交互式程序来解决，我们在本节中详细介绍。使用我们的技术，可以在线获取身份。此外，尽管轨迹与集群的关联（参见第  IV-F 节）可能是错误的，但由于用户集群的重叠，<strong>一旦轨迹再次分开，就会使用 DCNN 分类器的输出来纠正关联</strong>。请注意，仅利用 KF  是不可能的，因为它的内存相当于一个时间步长，不足以解决这个问题。接下来，正式描述该过程。</p>
<p>将分类器应用于来自 $ K_t $个当前轨迹的 μD 签名，返回 $K_t$ 个 U 维向量，其中包含每个轨迹属于 U（已知）用户类别之一的概率。因此，我们通过堆叠这些向量来构建一个 $K_t ×  U $矩阵 $F_t$。该矩阵在位置 (i, j) 中包含轨迹 i 属于主题 j ∈ {1, . . . , U}的概率。按照类似于第 IV-F 节的推理，我们可以将矩阵 $F_t$解释为轨迹和类别之间关联的得分矩阵。因此，当前时间步的标签的最优分配是通过在 -$F_t$  上再次应用匈牙利算法来获得的，它代表关联成本。这种方法可以联合标记所有轨迹。从匈牙利算法的性质来看，同一类永远不会分配给一个以上的主题。如果算法没有为她/他分配标签（如果 $ Kt &gt; U$，则会发生这种情况）或当 DCNN 输出的分数低于 0.1（我们设置的阈值以避免低概率关联时）则将受试者分类为未知 。</p>
<p>为了增强识别过程的稳定性，DCNN  在时间 t 输出的当前标签与过去的标签一起使用如下。</p>
<ol>
<li>对于每个轨迹，我们将  DCNN 输出的过去标签存储在一个列表中。</li>
<li>在 t = 0 时，使用瞬时标签识别受试者，因为没有过去的信息可用。</li>
<li>在时间步  t &gt; 0 时，每个轨迹 i 都根据 DCNN 分类器在时间 t 之前输出的最新$ Wh$ 个标签进行分类，即在时间步$ (t - W_h + 1) ，. . . , (t - 1), t$处。如果所有这些 $W_h $标签都匹配，我们将它们的共同值分配给轨迹；这将是在时间 t  输出的最终身份标签。相反，如果此列表中出现不同的值，我们将保留先前在时间 (t-1) 分配给轨迹 i 的最终标签。请注意，如果列表中任何轨迹 i 的 $W_h  $个值不同，则该过程将保持先前的标签，直到 DCNN 将输出一系列 Wh 个匹配的标签。</li>
</ol>
<p>我们注意到，对于任何轨迹，<strong>Wh  的值编码了接受算法输出的身份变化所需的时间稳定性水平</strong>。事实上，这个过程在识别中引入了额外的稳定性，因为避免了只持续几个时间步的错误分类。然而，当发生跟踪错误时，例如，<strong>当用户之间交换轨迹时，就校正速度而言是要付出代价的</strong>。因此，必须在识别结果的稳定性（大  Wh）和补偿跟踪误差的延迟（小 Wh）之间确定理想的折衷。</p>
<h2 id="5-EXPERIMENTAL-RESULTS"><a href="#5-EXPERIMENTAL-RESULTS" class="headerlink" title="5. EXPERIMENTAL RESULTS"></a>5. EXPERIMENTAL RESULTS</h2><h3 id="A-Measurement-Setup-and-Parameters"><a href="#A-Measurement-Setup-and-Parameters" class="headerlink" title="A. Measurement Setup and Parameters"></a>A. Measurement Setup and Parameters</h3><p>使用工作在  77 GHz 中心频率的 INRAS RadarLog 设备对所提出的框架进行了评估。前端具有 2 个发射天线和 16  个接收天线，组成一个线性阵列。设备工作参数设置如表一所示。在 LFMCW 模式下工作，我们分别使用1个发射天线和 L = 16  个接收天线。为了获得多目标测量的地面真实值，我们使用了与雷达设备时间同步的相机：生成的视频用于识别和跟踪室内空间内的用户。</p>
<p>为了彻底评估所提议的系统，我们使用了两个尺寸、形状和传播环境截然不同的测量室，进行了几次测量活动。</p>
<p>测量室  A 是一个 4.3 × 20 m 的走廊，其中雷达位于短边，如图 5 所示。这使得我们的评估室非常具有挑战性。房间 A  是这项工作中考虑的主要环境，其中进行了大部分测试，同时收集了分类器的训练数据。</p>
<p><img src="http://picgo.southner.top/image-20220511101415622.png" alt="image-20220511101415622"></p>
<p>测量室 是一个 8 × 4 m  的研究实验室，家具和设备留在原处，以模拟真实的室内场景。此外，<strong>房间内也有其他未参与测量的人员在跟踪区域之外</strong>，进一步增加了跟踪和识别任务的难度。房间 B  用于验证我们的方法并研究分类器的泛化能力，该分类器仅使用来自房间 A 的数据进行训练。</p>
<p>我们收集了雷达数据，用于训练和验证我们的算法，用于以下实验。</p>
<ol>
<li>Training the Classifier on Single Subjects (Room A)： 我们收集了来自年龄从  24 到 31 岁、体型和体重不同的四个不同受试者（S1、S2、S3 和 S4）的 RDA 数据。要求每个受试者在测量室内不受任何限制地独自行走约 22  分钟，收集 20 个 500 帧的序列，每个受试者总共 10000 帧。这些序列是在两天内获得的，以减少衣服或身体状况的影响。</li>
<li>Evaluating the Performance of RD Multiperson Identification (Room A): 我们获得了  1、250 个仅 <strong>RD 帧</strong>的 4 个测试序列，其中 2 个具有 2 个目标（S1 和 S2），另外 2 个具有 3 个目标（S1、S2 和  S3）。所有受试者都被要求自由行走，没有空间限制和改变他们的步行速度。</li>
<li>Evaluating the Performance of RDA Multiperson Identification (Room A): 我们获得了  500 个 <strong>RDA 帧</strong>的 6 个测试序列和 4  个目标。为了使测试更具挑战性，我们让目标以方形方式行走，前两个对象和后两个对象与雷达设备的距离相同，两者之间的距离约为 1 米对，如图 5  所示。所有目标都被限制以（大约）相同的速度行走。此设置是有意选择的，因为它代表了基于 RDA  的系统的最坏情况。事实上，在这种情况下，主体无法通过不同的速度或范围来区分，检测/跟踪，主要依靠角度信息，不如范围或速度准确。而且，分类器是强制的<strong>根据对受试者行走方式进行编码的μD频谱图的特征</strong>做出身份决策，因为他们的速度是相同的。我们强调这种类型的分析是新的：通常，基于神经网络的  μD 分类器将非信息性平均步行速度作为判别特征，当受试者具有相似的速度时，导致准确性较差，例如 [1]。</li>
<li><p>Validating the Performance in a Different Measurement Room (<strong>Room B</strong>): 我们在不同环境中收集了两个受试者的  RDA 数据，以评估系统，特别是 DCNN 分类器是否可以泛化到一个看不见的领域。在分类器的训练过程中不使用房间 B 的数据。在房间 B 中获得的 2  个序列每个包含 500 帧，并且受试者的行走模式受到类似于第 3 点的约束。房间边界值（见第 IV-G  节）已根据新房间尺寸进行了修改，以有效处理幽灵目标。请注意，房间 B 的实验只涉及两名受试者，因为相对于房间 A，可用的步行空间减少了。但是，房间 B  的每平方米用户密度更高，这再次对应于更具挑战性的设置。</p>
<p>考虑到参数后，原始雷达帧的形状分别为  N × L × P = 512 × 16 × 256 个沿快时、天线元件和慢时维度<strong>(范围 角度 速度？)</strong>的点。我们沿<strong>角度维度</strong>使用 64 个点用于 DFT，沿<strong>多普勒维度</strong>使用 256  个点用于 DFT。对于<strong>范围维度</strong>，我们为 DFT 使用了 1024 个点，对于 RDA 数据（253 个 bin）提取范围从 0 到 10 m，对于 RD  地图（497 个 bin）提取范围从 0 到 18 m。通过<strong>切割</strong> 8 个中央多普勒通道（对应于 [−0.138, 0.138] m/s  范围内的速度）和第一个和最后 24 个通道(the first and last 24 channels)对应于区间 [−3.160, 3.160 ] m/s 外的也被删除，因为它们不包含任何有用的信息。在 DFT  处理后得到的雷达图对于 RDA 的维度为 253 × 64 × 200 点，对于 RD 为 497 × 200 点，这对应于 RDA 的数据帧大小相对于 RD  增加了 34 倍。我们通过对范围和角度维度求和来执行 μD 提取，获得具有 200 个多普勒bins和可变时间长度的频谱图，具体取决于序列（500 或 1250  帧）。</p>
</li>
</ol>
<p>在使用  RD DFT 处理时，一个常见的假设是目标在单个帧周期内覆盖的距离小于距离 bin 的长度，即$ v PT_{rep} &lt; \Delta R$，其中 v  是对象的速度。如果不满足此假设，则来自目标的回波会跨越多个距离箱（<strong>距离迁移</strong>）[29]、[30]。然而，在我们的案例中，这种影响是无害的，其中人类受试者沿范围维度的典型延伸从  0.5 到 1.5 m，对应于 6-20 个范围箱。事实上，人类受试者在室内环境中的平均步行速度约为 1.5 m/s [31]，这导致测距精度最多降低 1-2  个距离箱，这对于目标大小而言可以忽略不计。</p>
<h3 id="B-Training-Phase"><a href="#B-Training-Phase" class="headerlink" title="B. Training Phase"></a>B. Training Phase</h3><p>我们使用  TensorFlow 2.0 和 Keras 应用程序编程接口 (API) 实现了分类器网络。训练是在 NVIDIA RTX 2080 GPU 上进行的，内存为  8 GB。</p>
<p>从房间  A 的测量中获得的每个目标的 20 μD 序列沿时间维度分成 30 帧的窗口，重叠 25 帧。将得到的图像分为训练集和验证集，分别占图像的 90% 和  10%，并对多目标序列进行测试。应用数据增强来扩大训练集：对于每个训练图像，我们通过以下方式生成 4 个附加图像</p>
<ol>
<li>添加均值为零且方差为 0.05 的高斯噪声，</li>
<li>将图像中的像素设置为零，概率为 0.3（随机损坏），</li>
<li>从随机均匀选择的索引开始，将  8 个相邻列（时间范围）设置为零（时间屏蔽）</li>
<li>从随机均匀选择的索引开始,将20 个相邻的多普勒箱设置为零 （频率掩蔽）。</li>
</ol>
<p>这些图像被用作编码器的输入  X，将解码器输出的重建目标 $\hat X$  设置为原始图像，以强制编码器-解码器对学习输入的关键结构属性（相同的策略被用于训练去噪自动编码器（DAE）[32]）。使用随机梯度下降 (SGD)  优化器在训练集上对模型进行训练，直到在验证集上收敛 (26) 中的损失 $L(\hat X, X, y)$，其中 Nesterov 动量为 0.95 且$ α_{rec}$ =  0.6。当验证损失在超过 5 个连续的epoch内没有改善时，学习率自适应地降低了 0.5 倍，初始值 η = 5 · 10-3。我们对网络权重应用系数 λ = 3  · 10−3 的 L2 正则化，对 FC 层应用概率 $p_{drop}$ = 0.5 的 dropout，以减少对训练数据的过度拟合。</p>
<p>在推理时间方面，所提出的  DCNN 平均需要 24 ms 来执行 2 s 长 μD 输入的分类。所有跟踪目标的 μD  签名以单个批次的形式馈送到网络，因此在一个时间步中只执行一次前向传递。</p>
<h3 id="C-DCNN-Evaluation-on-the-IDRad-Data-Set-Single-T-arget"><a href="#C-DCNN-Evaluation-on-the-IDRad-Data-Set-Single-T-arget" class="headerlink" title="C. DCNN Evaluation on the IDRad Data Set (Single-T arget)"></a>C. DCNN Evaluation on the IDRad Data Set (Single-T arget)</h3><p>作为第一个评估阶段，我们在  IDRad 上训练和验证了提出的 DCNN，一个公开可用的 77 GHz 雷达 μD 特征数据集 [1]。该数据集包含来自 5 个不同受试者的 RD  帧，一次在环境中行走一个，因此，使用该数据集无法进行多目标识别。训练和验证/测试数据在两个不同的房间收集。</p>
<p>使用 IDRad 数据集，我们评估了我们的框架在单人识别问题上的性能，并将其与可用的基准 [1]、[3]、[10]  进行了比较。为了与之前的工作进行公平的比较，我们调整了 DCNN 以接受长度为 45 帧而不是 30 帧的 μD  序列作为输入。我们发现我们的分类器泛化性很好，总体平均准确率为 90.69%，在不同的帧之间略有不同目标，但始终高于  88%。我们的方法的性能与文献中的方案之间的比较如表 II 所示。我们的分类器是最准确的，明显优于之前的 DCNN 方法 [1]，该方法基于水库计算网络  (RCN) [10]，并且性能略好于 [3]，其中结构化推理网络 (SIN) 和 LSTM使用递归神经网络（LSTM）。我们相信这种改进是由于使用了  IBs，它允许在不同尺度上提取特征，而不会显着增加网络复杂度，这很容易导致过度拟合。</p>
<p><img src="http://picgo.southner.top/image-20220511103632070.png" alt="image-20220511103632070"></p>
<h3 id="D-Performance-Metrics"><a href="#D-Performance-Metrics" class="headerlink" title="D. Performance Metrics"></a>D. Performance Metrics</h3><p>为了在多目标设置中训练和测试提议的处理管道，我们在多个测量活动中收集了我们自己的 RD 和 RDA 数据（参见第 V-A 节）。最终分类器的性能根据 1)  <strong>准确度</strong>来评估，即正确识别目标的帧数与检测到目标并分配为非未知标签的帧数之间的比率（参见第 IV-J) 节；  2）<strong>未检测到的比率</strong>undetected ratio（$r_{und}$），即未检测到目标的帧数与收集的总帧数之间的比率；  3）<strong>未知比率</strong>unknown ratio（$r_{unk}$），目标被标记为未知的帧数与收集到的总帧数之间的比率。最后一个指标是对识别框架在为目标提供分类时的不确定性的度量。</p>
<h3 id="E-Results-for-the-RD-Signal-Multitarget"><a href="#E-Results-for-the-RD-Signal-Multitarget" class="headerlink" title="E. Results for the RD Signal (Multitarget)"></a>E. Results for the RD Signal (Multitarget)</h3><p>在表 III 中，我们使用第 V-D 部分的指标报告每个受试者的结果，在测试序列上取平均值。在评估中，我们丢弃了轨迹需要累积 30 帧 μD  数据的初始阶段，以便将第一张图像提供给 DCNN 分类器。</p>
<p><img src="http://picgo.southner.top/image-20220511104103974.png" alt="image-20220511104103974"></p>
<p>使用  RD maps，两个目标的案例准确率最高，平均为 97.96%。正如人们所预料的那样，对于三个目标，某些受试者的 $r_{und}$  会增加：在同一区域拥有更多目标会导致其集群重叠的概率更高。在这种情况下，无法检测到来自目标 2 的反射，因为该用户的 27% 帧与 RD  空间中其他用户的帧重叠（因为它们具有相似的范围和速度）。然而，有趣的一点是，对于两个目标的情况，识别accuracy和$r_{unk}$没有受到显着影响，这意味着识别框架可以从漏检中恢复，当目标再次可检测时仍然提供高精度。</p>
<p>对错误的详细分析表明，RD  处理的主要问题是 RD 空间中集群的叠加：当对象具有相似的范围和速度时，就会发生这种情况，很可能被检测为单个集群。这是 RD  空间的固有限制，不受任何系统参数的影响。然而，由于所提出的处理方法允许在集群分离后重新建立轨迹，并使用识别结果纠正错误（参见第 IV-J  节），系统仍然在非常高的时间内提供正确的结果。文献中的其他技术分别处理跟踪和识别，因此无法处理多目标 RD 识别，因为它们无法从错误跟踪中恢复。</p>
<p>作为最后一个结果，在图  6 中，我们展示了沿多普勒轴 wB 改变框尺寸的影响，平均在两个目标上获得的精度。正如预期的那样，在捕获大部分目标的多普勒信息（大  wB）和避免框之间不必要的重叠（小 wB）之间存在权衡，这可能导致分类错误。表 III 结果的选择值为 2.5  m/s，因为它提供了最高精度。盒子沿范围维度的维度 $h_B$ 保持固定在 2 m。</p>
<p><img src="http://picgo.southner.top/image-20220511104438346.png" alt="image-20220511104438346"></p>
<h3 id="F-Results-for-the-RDA-Signal-Multitarget"><a href="#F-Results-for-the-RDA-Signal-Multitarget" class="headerlink" title="F . Results for the RDA Signal (Multitarget)"></a>F . Results for the RDA Signal (Multitarget)</h3><p>表  III 显示了 6 个测试序列的平均 RDA 处理结果：我们的系统在 4 个目标上实现了 98.27% 的准确度。我们回想一下，DCNN 必须收集前 30 μD  向量的初始阶段在计算中被忽略，并且对于 RD 分析，仅考虑此初始瞬态周期之后的帧。</p>
<p>相对于  RD 分析中较高的人口密度（0.1 人/平方米），导致阻塞变得更加频繁，即一些受试者在某些帧期间阻塞了到其他目标的信号路径，这解释了 9.35%  的$r_{und}$.相反，对于所有受试者和所有序列，runk  总是为零，这意味着一旦检测到目标，网络总是有足够的数据和置信度来产生分类结果。值得注意的是，尽管所有受试者的$r_{und}$ 都大于零，但识别准确度仍然非常高（特别参见 S3），这再次证实了框架从漏检中恢复的能力。由于第 IV-J 节的校正算法，这是可能的。</p>
<p><img src="http://picgo.southner.top/image-20220511104809117.png" alt="image-20220511104809117"></p>
<h3 id="G-Impact-of-Training-Parameters"><a href="#G-Impact-of-Training-Parameters" class="headerlink" title="G. Impact of Training Parameters"></a>G. Impact of Training Parameters</h3><p>所提出的  DCNN 架构，在 IB 的数量、FC  层的数量和跳过连接的存在方面，是使用超参数上的<strong>贪婪搜索</strong>过程获得的，即，我们通过一次更改一个参数并选择导致损失最小的值。这个过程相对于穷举搜索或贝叶斯方法来说是次优的，但由于其较低的计算成本而被首选。下面，我们重点关注最有趣和最有影响力的参数，即  <strong>$α_{rec} $的值和数据增强的使用</strong>，分析它们对最终测试精度的影响。重建权重 αrec ∈ [0, 1]  调整了分类和重建分支在训练损失中的相对重要性。使用重建分支已经证明可以稍微提高 DCNN 的泛化能力，类似于使用正则化通常实现的效果。具体来说，在图 7  中，我们绘制了从 0（即禁用重建分支）到 0.9 变化的 αrec 获得的准确度值。 αrec = 0.6  时获得最佳结果。值得注意的是，这些改进<strong>只有在将编码器-解码器结构与第 V-B  节中描述的数据增强策略结合使用时才有可能</strong>。事实上，在没有数据增强（例如，噪声添加和随机信号删除/损坏）的情况下，自动编码器输出端的重建变得更加容易，并且特征提取在捕获真实信号流形方面的效率较低。结果，没有观察到主要的好处。</p>
<p><img src="http://picgo.southner.top/image-20220511105046289.png" alt="image-20220511105046289"></p>
<p>在表  IV 中，我们展示了仅使用总训练数据的一部分对完成训练所需的时间以及对 RDA 测试数据的准确性的影响。虽然使用 25%、50%、75% 或 100%  的完整训练集（每个受试者 22 分钟）时训练时间几乎呈线性增加，但从 75% 到 100%  时，准确度的提高最小。这是对模型性能的饱和效应，这在神经网络训练中很常见。在表 IV  的最后一列中，我们展示了在不利用数据增强的情况下在整个可用数据集上训练模型的结果。准确性显着降低，促使人们使用第 V-B 节中描述的增强技术。</p>
<p><img src="http://picgo.southner.top/image-20220511105119268.png" alt="image-20220511105119268"></p>
<h3 id="H-Integrated-V-ersus-Separate-Tracking-and-Identification"><a href="#H-Integrated-V-ersus-Separate-Tracking-and-Identification" class="headerlink" title="H. Integrated V ersus Separate Tracking and Identification"></a>H. Integrated V ersus Separate Tracking and Identification</h3><p>如第  IV-J 节所述，所提出的系统联合执行跟踪和识别。为了量化这种设计在分别获得轨迹和身份方面的改进，我们量化了在所有考虑的受试者和 RD/RDA  测试序列上应用两种方法（联合处理与单独处理）时平均准确度的差异。图 8 证实了我们的综合方法对于实现精确的 RD 识别至关重要，在 3 个和 2  个受试者案例上分别提高了 36.32% 和 25.42%。对于 RDA 处理，改进较小（8.91%），因为系统在 RDA  空间中的检测能力更高，这使得聚类叠加和后续跟踪错误的频率较低。然而，改进是不可忽略的，并且所提出的组合架构仍然非常有效。</p>
<p><img src="http://picgo.southner.top/image-20220511105246472.png" alt="image-20220511105246472"></p>
<h3 id="I-Dimensioning-the-Classification-Window-Wh"><a href="#I-Dimensioning-the-Classification-Window-Wh" class="headerlink" title="I. Dimensioning the Classification Window Wh"></a>I. Dimensioning the Classification Window Wh</h3><p>正如第 IV-J 节所预期的那样，<strong>分类窗口参数</strong> Wh 在在线分类准确性和从错误中恢复的速度之间的权衡中起着重要作用。在图 9 中，我们展示了将 Wh 从 1  帧变为 20 帧对 RDA 信号的影响。考虑了所有 6  个序列，我们观察到准确性的单调递增行为。尽管情况并非总是如此：如果分类器的初始猜测是错误的，即使在没有跟踪错误的情况下，较大的窗口值也会导致许多帧的分类错误。出于这个原因，一个好的选择方法是<strong>选择尽可能低的  Wh，以保证给定的、依赖于应用程序的准确度目标</strong>。对于表 III 中的结果，我们选择了 Wh = 9 帧，导致延迟为 0.6 秒，因此所有序列的准确率均高于  95%。尽管如此，直到 Wh = 15 帧的所有值都是不错的选择，因为所有这些值的延迟都低于 1 秒。相同的 Wh 值在 RD 情况下也产生了最好的结果。</p>
<p><img src="http://picgo.southner.top/image-20220511105321144.png" alt="image-20220511105321144"></p>
<h3 id="J-V-alidation-in-a-Different-Indoor-Environment"><a href="#J-V-alidation-in-a-Different-Indoor-Environment" class="headerlink" title="J. V alidation in a Different Indoor Environment"></a>J. V alidation in a Different Indoor Environment</h3><p>为了分析所提出系统的泛化能力，我们评估了它在不同环境（房间  B）中的性能，如第 V-A 节所述，考虑 RDA 处理。在这里，我们研究了预训练的 DCNN  是否可以很好地泛化到新房间，因为对于每个新环境重复训练过程太长且成本太高。幽灵目标去除和 KF 矩阵的检测和跟踪参数可以与环境无关（例如，KF  参数），可以很容易地从侧面信息（房间尺寸）中获得，或者可以通过对空房间进行一些初步测量来估计（去噪阈值）。具体来说，新的范围相关去噪阈值从最小范围的 -75  dBm 变为 -95 dBm，考虑到较小的房间尺寸和大量静态物体的存在，这是可以预期的。相反，方位角维度上的阈值保持不变。</p>
<p>在表 V 中，我们展示了测试结果，在房间 B 中，在房间 A 中训练的分类器。在 2 个考虑的序列上，2 名受试者的平均准确率为 96%，低于在 A 室中获得的  4 名受试者的准确率，但考虑到新环境的困难传播条件，被认为是令人满意的。事实上，我们强调房间 B  包含家具和几个静态物体，这些物体会导致严重的多路径效应和杂乱，此外还有其他正在工作且未参与实验的人的存在。这些严酷的条件反映在无法检测到对象的时间百分比很高，即  rund = 18.60%，即相对于房间 A 几乎翻了一番（见表  III）。我们得出结论，即使在现实条件下，分类器也能够推广到看不见的环境：更可靠的检测方案将进一步增强模型的鲁棒性，我们将他们的研究留作未来的工作。</p>
<p><img src="http://picgo.southner.top/image-20220511105555940.png" alt="image-20220511105555940"></p>
<h2 id="6-CONCLUSION"><a href="#6-CONCLUSION" class="headerlink" title="6. CONCLUSION"></a>6. CONCLUSION</h2><p>在这项工作中，我们提出了一个基于毫米波雷达  μ-多普勒特征的室内多人识别系统。所提出的方法旨在处理 RD 和 RDA 数据，只需要进行小的修改即可处理这两个信号，并且能够以工作范围和计算速度 (RD)  换取检测和跟踪精度 (RDA)。处理步骤是：去除静态反射和随机噪声、使用基于密度的聚类 (DBSCAN) 的目标检测阶段、使用卡尔曼滤波的跟踪过程和利用  DCNN 的最终分类步骤。在我们的新颖设计中，我们将识别信息与轨迹跟踪块集成在一起。这具有双重优势，即在多目标场景中同时使用 RD 和 RDA  信号时允许更高的识别精度，即多个对象在同一物理空间内共享和移动。所提出的框架已经在涉及在室内空间中同时移动的单个和多个目标的实际测量中进行了测试（文献中缺乏的一个方面），对于  RD、3 个目标和 98.27% 的识别准确度达到了 3 个目标。 RDA，有 4 个目标。该框架对于 RD 的最大工作范围为 18 m，对于 RDA  的最大工作范围为 8-10  m。进行了进一步的评估，以评估所提出方法的普遍性，通过在不同的房间中捕获额外的测试数据，这些数据在训练时未被系统使用。尽管新环境更具挑战性，例如家具和其他人的存在，但我们在两个科目中获得了  96% 的准确率。</p>
<p>未来的研究途径包括：通过（自动）映射静态物体和鬼反射来表征室内空间，这有望提高精度，使用多个时间同步雷达设备和二维天线阵列（仰角）。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://southner.top">southner</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://southner.top/2022/06/17/%E3%80%8AMultiperson-Continuous-Tracking-and-Identification-From-mm-Wave-Micro-Doppler-Signatures%E3%80%8B%E9%98%85%E8%AF%BB/">http://southner.top/2022/06/17/《Multiperson-Continuous-Tracking-and-Identification-From-mm-Wave-Micro-Doppler-Signatures》阅读/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://southner.top" target="_blank">南风er的小窝</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/mmwave%E9%9B%B7%E8%BE%BE/">mmwave雷达</a></div><div class="post_share"><div class="social-share" data-image="http://picgo.southner.top/cover7.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/06/17/RADDet%E5%B7%A5%E4%BD%9C%E5%A4%8D%E7%8E%B0/" title="RADDet工作复现"><img class="cover" src="http://picgo.southner.top/cover5.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-17</div><div class="title">RADDet工作复现</div></div></a></div><div><a href="/2022/06/17/%E3%80%8ARADDet-Range-Azimuth-Doppler-based-Radar-Object-Detection-for-Dynamic-Road-Users%E3%80%8B%E9%98%85%E8%AF%BB/" title="《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读"><img class="cover" src="http://picgo.southner.top/cover7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-17</div><div class="title">《RADDet: Range-Azimuth-Doppler Based Radar Object Detection for Dynamic Road Users》阅读</div></div></a></div><div><a href="/2022/06/17/%E3%80%8AmmSense-Multi-Person-Detection-and-Identification-via-mmWave-Sensing-19%E3%80%8B%E9%98%85%E8%AF%BB/" title="《mmSense: Multi-Person Detection and Identification via mmWave Sensing 19》阅读"><img class="cover" src="http://picgo.southner.top/cover12.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-17</div><div class="title">《mmSense: Multi-Person Detection and Identification via mmWave Sensing 19》阅读</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-Abstract"><span class="toc-text">0. Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-INTRODUCTION"><span class="toc-text">1. INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-RELATED-WORK"><span class="toc-text">2. RELATED WORK</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-MM-WAVE-RADAR-SIGNAL-MODEL"><span class="toc-text">3. MM-WAVE RADAR SIGNAL MODEL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Range-Doppler-and-Azimuth-Information"><span class="toc-text">A. Range, Doppler and Azimuth Information</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%CE%BC-Doppler-Map"><span class="toc-text">B. μ-Doppler Map</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-PROPOSED-ALGORITHM"><span class="toc-text">4.PROPOSED ALGORITHM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Overview-of-the-Signal-Processing-Pipeline"><span class="toc-text">A. Overview of the Signal Processing Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Notation"><span class="toc-text">B. Notation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-Preprocessing"><span class="toc-text">C. Preprocessing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#D-Target-Clustering-in-RD-RDA-Spaces%E2%80%93DBSCAN"><span class="toc-text">D. Target Clustering in RD&#x2F;RDA Spaces–DBSCAN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#E-Trajectory-Tracking%E2%80%93Kalman-Filter"><span class="toc-text">E. Trajectory Tracking–Kalman Filter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#F-Matching-Trajectories-to-Clusters%E2%80%93Hungarian-Algorithm"><span class="toc-text">F . Matching Trajectories to Clusters–Hungarian Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#G-Trajectory-Management"><span class="toc-text">G. Trajectory Management</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#H-Computation-of-%CE%BCD-Time-Series"><span class="toc-text">H. Computation of μD Time Series</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#I-Identification%E2%80%93DCNN"><span class="toc-text">I. Identification–DCNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#J-Labeling-and-Trajectory-Correction-Procedure"><span class="toc-text">J. Labeling and Trajectory Correction Procedure</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-EXPERIMENTAL-RESULTS"><span class="toc-text">5. EXPERIMENTAL RESULTS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Measurement-Setup-and-Parameters"><span class="toc-text">A. Measurement Setup and Parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Training-Phase"><span class="toc-text">B. Training Phase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-DCNN-Evaluation-on-the-IDRad-Data-Set-Single-T-arget"><span class="toc-text">C. DCNN Evaluation on the IDRad Data Set (Single-T arget)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#D-Performance-Metrics"><span class="toc-text">D. Performance Metrics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#E-Results-for-the-RD-Signal-Multitarget"><span class="toc-text">E. Results for the RD Signal (Multitarget)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#F-Results-for-the-RDA-Signal-Multitarget"><span class="toc-text">F . Results for the RDA Signal (Multitarget)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#G-Impact-of-Training-Parameters"><span class="toc-text">G. Impact of Training Parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#H-Integrated-V-ersus-Separate-Tracking-and-Identification"><span class="toc-text">H. Integrated V ersus Separate Tracking and Identification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#I-Dimensioning-the-Classification-Window-Wh"><span class="toc-text">I. Dimensioning the Classification Window Wh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#J-V-alidation-in-a-Different-Indoor-Environment"><span class="toc-text">J. V alidation in a Different Indoor Environment</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-CONCLUSION"><span class="toc-text">6. CONCLUSION</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By southner</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="http://www.beian.miit.gov.cn/"><img class="icp-icon" src="https://pic3.zhimg.com/80/v2-d0289dc0a46fc5b15b3363ffa78cf6c7.png"><span>陕ICP备20012321号</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>